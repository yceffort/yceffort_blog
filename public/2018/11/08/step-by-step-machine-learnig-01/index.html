
<!DOCTYPE html>
<html lang="en">
    

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="yceffort">
    <meta name="google-site-verification" content="TRGuZGQqLhBScdz5opOQ5vD2jLwfHmWrWdze_xY0EbQ" />

    <title>Step by Step machine laerning - 01 - yceffort</title>
    <meta name="author" content="yceffort">
    
    <meta name="keywords" content="programming,innovation,technology,">
    
    <link rel="apple-touch-icon" sizes="57x57" href="/images/favicon/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/images/favicon/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/images/favicon/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/images/favicon/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/images/favicon/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/images/favicon/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/images/favicon/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/images/favicon/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192" href="/images/favicon/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="/images/favicon/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png">
    <link rel="manifest" href="/images/favicon/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/images/favicon/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">
    
    <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"yceffort","sameAs":["https://github.com/yceffort","mailto: root@yceffort.kr"],"image":"https://www.gravatar.com/avatar/f24f66c6311c477d8ac26a9ef346560c"},"articleBody":"California Housing 데이터를 바탕으로 scikt-learn을 활용한 머신러닝 예제.\n¶1. 기본적인 데이터 로딩\n프록시 환경이라, 프록시를 핸들러에 추가하였습니다.\n1234567891011121314151617181920212223242526272829303132import osimport tarfilefrom six.moves import urllibimport numpy as npimport pandas as pd# 데이터 로딩HOUSING_PATH = os.path.join(\"datasets\", \"housing\")HOUSING_URL = \"http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.tgz\"def fetching_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):    if not os.path.isdir(housing_path):        os.makedirs(housing_path)            proxy = urllib.request.ProxyHandler(&#123;'http': 'http://proxy.url', 'https':'http://proxy.url'&#125;)    opener = urllib.request.build_opener(proxy)    urllib.request.install_opener(opener)    tgz_path = os.path.join(housing_path, \"housing.tgz\")    urllib.request.urlretrieve(housing_url, tgz_path)    housing_tgz = tarfile.open(tgz_path)    housing_tgz.extractall(path=housing_path)    housing_tgz.close()fetching_housing_data()def load_housing_data(housing_path=HOUSING_PATH):    csv_path = os.path.join(housing_path, \"housing.csv\")    return pd.read_csv(csv_path)housing = load_housing_data()housing.head()\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      median_house_value\n      ocean_proximity\n    \n  \n  \n    \n      0\n      -122.23\n      37.88\n      41.0\n      880.0\n      129.0\n      322.0\n      126.0\n      8.3252\n      452600.0\n      NEAR BAY\n    \n    \n      1\n      -122.22\n      37.86\n      21.0\n      7099.0\n      1106.0\n      2401.0\n      1138.0\n      8.3014\n      358500.0\n      NEAR BAY\n    \n    \n      2\n      -122.24\n      37.85\n      52.0\n      1467.0\n      190.0\n      496.0\n      177.0\n      7.2574\n      352100.0\n      NEAR BAY\n    \n    \n      3\n      -122.25\n      37.85\n      52.0\n      1274.0\n      235.0\n      558.0\n      219.0\n      5.6431\n      341300.0\n      NEAR BAY\n    \n    \n      4\n      -122.25\n      37.85\n      52.0\n      1627.0\n      280.0\n      565.0\n      259.0\n      3.8462\n      342200.0\n      NEAR BAY\n    \n  \n\n1housing.info()\n123456789101112131415&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;RangeIndex: 20640 entries, 0 to 20639Data columns (total 10 columns):longitude             20640 non-null float64latitude              20640 non-null float64housing_median_age    20640 non-null float64total_rooms           20640 non-null float64total_bedrooms        20433 non-null float64population            20640 non-null float64households            20640 non-null float64median_income         20640 non-null float64median_house_value    20640 non-null float64ocean_proximity       20640 non-null objectdtypes: float64(9), object(1)memory usage: 1.6+ MB\nocean_proximity는 텍스트로 정보가 들어가 있는 것 같다.\n1housing['ocean_proximity'].value_counts()\n123456&lt;1H OCEAN     9136INLAND        6551NEAR OCEAN    2658NEAR BAY      2290ISLAND           5Name: ocean_proximity, dtype: int64\n1housing.describe()\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      median_house_value\n    \n  \n  \n    \n      count\n      20640.000000\n      20640.000000\n      20640.000000\n      20640.000000\n      20433.000000\n      20640.000000\n      20640.000000\n      20640.000000\n      20640.000000\n    \n    \n      mean\n      -119.569704\n      35.631861\n      28.639486\n      2635.763081\n      537.870553\n      1425.476744\n      499.539680\n      3.870671\n      206855.816909\n    \n    \n      std\n      2.003532\n      2.135952\n      12.585558\n      2181.615252\n      421.385070\n      1132.462122\n      382.329753\n      1.899822\n      115395.615874\n    \n    \n      min\n      -124.350000\n      32.540000\n      1.000000\n      2.000000\n      1.000000\n      3.000000\n      1.000000\n      0.499900\n      14999.000000\n    \n    \n      25%\n      -121.800000\n      33.930000\n      18.000000\n      1447.750000\n      296.000000\n      787.000000\n      280.000000\n      2.563400\n      119600.000000\n    \n    \n      50%\n      -118.490000\n      34.260000\n      29.000000\n      2127.000000\n      435.000000\n      1166.000000\n      409.000000\n      3.534800\n      179700.000000\n    \n    \n      75%\n      -118.010000\n      37.710000\n      37.000000\n      3148.000000\n      647.000000\n      1725.000000\n      605.000000\n      4.743250\n      264725.000000\n    \n    \n      max\n      -114.310000\n      41.950000\n      52.000000\n      39320.000000\n      6445.000000\n      35682.000000\n      6082.000000\n      15.000100\n      500001.000000\n    \n  \n\n그래프로 보자\n12345%matplotlib inlineimport matplotlib.pyplot as plt# bins는 막대의 두께, figsize는 그래프의 크기다.housing.hist(bins=100, figsize=(20, 15))plt.show()\n\n¶2. 데이터 분석\n이제 데이터를 test set과 train set으로 나눠 보자.\ntest_size 는 말그대로 테스트의 크기이고, random_states는 random값 생성을 위한 seed 값이다.\n12from sklearn.model_selection import train_test_splittrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n이렇게 랜덤하게 나누는 것은 데이터가 클때, 그리고 속성이 많을 때는 괜찮다. 그러나 그렇게 데이터가 많지 않으면, 샘플링을 하는 과정에서도 bias가 생길 수 있다. 만약 한국의 인구비가 6:4라면, 테스트 split을 할 때에도 6:4 로 성비가 뽑혀야 괜찮다고 할 수 있을 것이다. 이를 stratified sampling이라고 한다. 랜덤으로 뽑을 경우, 6:4를 보장할 수는 없을 것이다.\n다시 예제로 돌아와서, 만약 median_income이 median_housing_prices를 예측하는데 큰 요소라고 가정을 해보자. 그러기 위해선, 위에서의 예제 처럼 다양한 median_income을 카테고리화 해서 테스트 셋을 만드는 것이 중요할 것이다. 위 그림에서 볼 수 있듯이, median_income은 값이 너무나도 다양하므로, stratum처리를 해주지 않으면 테스트 셋을 랜덤하게 뽑아 낼 때마다 값이 널뛰기를 할 것이다.\n그래서, 1.5로 나눈다음 5보다 큰 값은 다 5로 replace 해버렸다.\n123housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)housing[\"income_cat\"].where(housing[\"income_cat\"] &lt; 5, 5.0, inplace=True)housing['income_cat'].hist(bins=10, figsize=(10, 5))\n\n이제 카테고리화 했으니, 카테고리에 다라서 균등하게 나눠보도록 합시다.\n123456789# 불균형한 데이터에 대해서 고르게 test, train set을 나눠준다.from sklearn.model_selection import StratifiedShuffleSplitsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)for train_index, test_index in split.split(housing, housing['income_cat']):    strat_train_set = housing.loc[train_index]    strat_test_set = housing.loc[test_index]strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)\n1234563.0    0.3505332.0    0.3187984.0    0.1763575.0    0.1145831.0    0.039729Name: income_cat, dtype: float64\n얼추 그래프의 분포와 비슷한 양상을 보이고 있다. 최초의 목적은 달성헀으니, 컬럼을 드랍하자.\n12345for set_ in (strat_train_set, strat_test_set):    set_.drop(\"income_cat\", axis=1, inplace=True)housing = strat_train_set.copy()housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n\n투명도를 넣어서 조금더 선명하게 보자.\n1housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\n\n조금더 이쁘장하게 만들어보자\n123456789101112housing.plot(kind=\"scatter\", #산점도             x=\"longitude\",              y=\"latitude\",              alpha=0.4, #투명도             s=housing['population'] / 100, #나타낼 데이터             label=\"population\", #라벨             figsize=(10, 7), #그래프 크기             c=\"median_house_value\", #색 부여할 데이터             cmap=plt.get_cmap(\"jet\"), #색             colorbar = True)plt.legend()\n\ncorrelation 매트릭스를 그려보자\n12corr_matrix = housing.corr()corr_matrix\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      median_house_value\n    \n  \n  \n    \n      longitude\n      1.000000\n      -0.924478\n      -0.105848\n      0.048871\n      0.076598\n      0.108030\n      0.063070\n      -0.019583\n      -0.047432\n    \n    \n      latitude\n      -0.924478\n      1.000000\n      0.005766\n      -0.039184\n      -0.072419\n      -0.115222\n      -0.077647\n      -0.075205\n      -0.142724\n    \n    \n      housing_median_age\n      -0.105848\n      0.005766\n      1.000000\n      -0.364509\n      -0.325047\n      -0.298710\n      -0.306428\n      -0.111360\n      0.114110\n    \n    \n      total_rooms\n      0.048871\n      -0.039184\n      -0.364509\n      1.000000\n      0.929379\n      0.855109\n      0.918392\n      0.200087\n      0.135097\n    \n    \n      total_bedrooms\n      0.076598\n      -0.072419\n      -0.325047\n      0.929379\n      1.000000\n      0.876320\n      0.980170\n      -0.009740\n      0.047689\n    \n    \n      population\n      0.108030\n      -0.115222\n      -0.298710\n      0.855109\n      0.876320\n      1.000000\n      0.904637\n      0.002380\n      -0.026920\n    \n    \n      households\n      0.063070\n      -0.077647\n      -0.306428\n      0.918392\n      0.980170\n      0.904637\n      1.000000\n      0.010781\n      0.064506\n    \n    \n      median_income\n      -0.019583\n      -0.075205\n      -0.111360\n      0.200087\n      -0.009740\n      0.002380\n      0.010781\n      1.000000\n      0.687160\n    \n    \n      median_house_value\n      -0.047432\n      -0.142724\n      0.114110\n      0.135097\n      0.047689\n      -0.026920\n      0.064506\n      0.687160\n      1.000000\n    \n  \n\n123# 1에 가까울 수록 긍정적으로 강한 관계가 있음.# -1에 가까울 수록 부정적으로 관계가 있음.corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n값은 ~1 부터 1 사이의 값을 가지며, 1에 가까울 수록 강한 positive 상관관계를, -1에 가까울 수록 강한 negative 상관관계를 갖는다.\n12345678910median_house_value    1.000000median_income         0.687160total_rooms           0.135097housing_median_age    0.114110households            0.064506total_bedrooms        0.047689population           -0.026920longitude            -0.047432latitude             -0.142724Name: median_house_value, dtype: float64\n0에 가까울 수록 아무런 관계가 없다는 것이다.\n\n상관관계가 있을 수록, plot이 우/좌상향 분포를 나타낸다. 과연 그런지 봅시다.\n1234from pandas.plotting import scatter_matrixattributes = ['median_house_value', 'median_income', 'total_rooms', 'housing_median_age']scatter_matrix(housing[attributes], figsize=(12, 8))\n\n1housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)\nmedian_income 과 median_house_value와 상관관계\n\n확실히 우상향 하는 분포를 띄고 있다.\n$500,000에 가로 선이 확실하게 보이는데, 이는 $450,000 과 $350,000에서도 뚜렷하게 보이고 있다.\n\n\n추가적으로, 몇가지 속성 값을 만들어보자.\n123456housing[\"rooms_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"]housing[\"population_per_household\"] = housing[\"population\"] / housing[\"households\"]corr_matrix = housing.corr()corr_matrix['median_house_value'].sort_values(ascending=False)\n1234567891011121314median_house_value          1.000000median_income               0.687160rooms_per_household         0.146285total_rooms                 0.135097housing_median_age          0.114110households                  0.064506total_bedrooms              0.047689population_per_household   -0.021985population                 -0.026920longitude                  -0.047432latitude                   -0.142724bedrooms_per_room          -0.259984Name: median_house_value, dtype: float64\n¶3. 머신러닝 알고리즘 활용을 위한  데이터 준비\n¶1) 데이터 클리닝\n일단, total_bedrooms 컬럼에 빈값들이 있는 것을 확인했다. 이 컬럼을 드랍하던지, 아니면 빈값을 적절하게 채우는 방법 이 있다. 빈값을 적절히 채우기 위해서는, 중간값(median)을 활용하는 것이 좋겠다.\n12from sklearn.preprocessing import Imputerimputer = Imputer(strategy=\"median\")\nmedian은 오로지 숫자 값만 처리할 수 있으므로, 숫자가 아닌 컬럼은 제거할 필요가 있다.\n1housing_num = housing.drop(\"ocean_proximity\", axis=1)\n그리고 imputer를 적용해보자.\n12345imputer.fit(housing_num)# 밑에 두개는 같은 결과를 보여준다.imputer.statistics_housing_num.median().values\n12array([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,        408.    ,    3.5409])\nimputer한 값을 다시 dataframe으로 가져오자.\n123X = imputer.transform(housing_num)housing_str = pd.DataFrame(x, columns=housing_num.columns)housing_str.head()\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n    \n  \n  \n    \n      0\n      -121.89\n      37.29\n      38.0\n      1568.0\n      351.0\n      710.0\n      339.0\n      2.7042\n    \n    \n      1\n      -121.93\n      37.05\n      14.0\n      679.0\n      108.0\n      306.0\n      113.0\n      6.4214\n    \n    \n      2\n      -117.20\n      32.77\n      31.0\n      1952.0\n      471.0\n      936.0\n      462.0\n      2.8621\n    \n    \n      3\n      -119.61\n      36.31\n      25.0\n      1847.0\n      371.0\n      1460.0\n      353.0\n      1.8839\n    \n    \n      4\n      -118.59\n      34.23\n      17.0\n      6592.0\n      1525.0\n      4459.0\n      1463.0\n      3.0347\n    \n  \n\n¶2) 텍스트와 카테고리 데이터 다루기\nocean_proximity는 우리가 문자여서 못썼다.\n12housing_cat = housing['ocean_proximity']housing_cat.head(10)\n123456789101117606     &lt;1H OCEAN18632     &lt;1H OCEAN14650    NEAR OCEAN3230         INLAND3555      &lt;1H OCEAN19480        INLAND8879      &lt;1H OCEAN13685        INLAND4937      &lt;1H OCEAN4861      &lt;1H OCEANName: ocean_proximity, dtype: object\n이렇게 하면 카테고리로 만들어 버릴 수 있다.\n123housing_cat_encoded, housing_categories = housing_cat.factorize()housing_cat_encoded[:10]housing_categories\n12array([0, 0, 1, 2, 0, 2, 0, 2, 0, 0])Index([&apos;&lt;1H OCEAN&apos;, &apos;NEAR OCEAN&apos;, &apos;INLAND&apos;, &apos;NEAR BAY&apos;, &apos;ISLAND&apos;], dtype=&apos;object&apos;)\n너의 text 적당한 number로 카테고리 되었다. Korean 불만있어요?\n근데 이렇게 한다면, 0과 1을 비슷한 값으로, 0과 4를 안비슷한 값으로 판단해버릴 것이다. 사실 숫자에는 별의미가 없기 때문에 저런일이 발생해서는 안된다. 그래서 사용하는 것이 one-hot encoding이다. one hot endoing은 이런 카테고리 데이터를 벡터화 하는 것이다. 여기에 잘 정리 되어 있다.\n12345678from sklearn.preprocessing import OneHotEncoderencoder = OneHotEncoder()# housing_cat_encoded는 횡방향으로 데이터를 길게 늘어뜨려 놓았다.# 데이터 프레임과 마찬가지 형식으로 종방향으로 데이터를 바꾸기 위해 reshape를 하였다.housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1, 1))housing_cat_1hot.toarray()\n1234567array([[1., 0., 0., 0., 0.],       [1., 0., 0., 0., 0.],       [0., 1., 0., 0., 0.],       ...,       [0., 0., 1., 0., 0.],       [1., 0., 0., 0., 0.],       [0., 0., 0., 1., 0.]])\n¶3) 커스텀 트랜스포머 만들기\n이제 이 과정을 데이터가 들어올 때 마다 일일히 할 수 없는 노릇이므로, 이를 자동화하는 과정을 만들어 보려고 한다. scikit-learn에서는 이러한 데이터 클린업 과정을 자동화 할 수 있는 Class를 만들 수 있다. 이를 위한 클래스에서 필요한 것은 fit(), (무조건 return self), transform(), fit_transform()이 세가지 메소드를 구현해야 한다. 그리고 이를 위해서는 TransformerMixin클래스를 더해야 한다. 추가로 BaseEstimator를 더하면,get_params()와 set_params()메소드도 구현할 수 있는데, 이는 hyperparameter를 튜닝할  때 유용하게 사용할 수 있다.\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546from sklearn.base import BaseEstimator, TransformerMixinrooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6# TransformerMixin Custom Cleanup Operation을 하기 위한 필수요소# 필수로 구현해야 하는 것# fit (return self)# transform () # fit_transform ()# BaseEstimator 는 (*args, **kargs)룰 피할 수 있으며# 두가지 method를 추가로 구현 가능, get_params(), set_params()# automatic hyperparameter tuning을 하는데 유용하다고함..# 아래예제에서는 add_bedrooms_per_room가 hyperparameter이며, 이 속성을 추가할지 여부를 결정할 수 있음.# 가변적으로 추가해야할 파라미터들이 있을 때 유용할 것으로 보임.class CombinedAttributesAdder(BaseEstimator, TransformerMixin):    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs        self.add_bedrooms_per_room = add_bedrooms_per_room    def fit(self, X, y=None):        return self  # nothing else to do    def transform(self, X, y=None):        # 가정당 방의 갯수를 구한다.        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]        # 가정당 인구 수를 구한다.        population_per_household = X[:, population_ix] / X[:, household_ix]        # add_bedroooms_per_room (이것이 hyperparameter다!!) 이 true면        if self.add_bedrooms_per_room:            # 방당 침실 수도 구한다.            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]            # 다 하나의 array로 합혀 준다.            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]        else:            return np.c_[X, rooms_per_household, population_per_household]# 위에서 만든걸 선언한다.attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)# 이를 바탕으로 housing의 값을 변경한다.housing_extra_attribs = attr_adder.transform(housing.values)# 새로 생긴 값을 추가해서 housing을 만든다.housing_extra_attribs = pd.DataFrame(housing_extra_attribs, columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"])housing_extra_attribs.head()\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      ocean_proximity\n      rooms_per_household\n      population_per_household\n    \n  \n  \n    \n      0\n      -121.89\n      37.29\n      38\n      1568\n      351\n      710\n      339\n      2.7042\n      &lt;1H OCEAN\n      4.62537\n      2.0944\n    \n    \n      1\n      -121.93\n      37.05\n      14\n      679\n      108\n      306\n      113\n      6.4214\n      &lt;1H OCEAN\n      6.00885\n      2.70796\n    \n    \n      2\n      -117.2\n      32.77\n      31\n      1952\n      471\n      936\n      462\n      2.8621\n      NEAR OCEAN\n      4.22511\n      2.02597\n    \n    \n      3\n      -119.61\n      36.31\n      25\n      1847\n      371\n      1460\n      353\n      1.8839\n      INLAND\n      5.23229\n      4.13598\n    \n    \n      4\n      -118.59\n      34.23\n      17\n      6592\n      1525\n      4459\n      1463\n      3.0347\n      &lt;1H OCEAN\n      4.50581\n      3.04785\n    \n  \n\n¶4. 모델 적용하기\n머신러닝을 할 때 중요한 것은 데이터 보정이다. 이 데이터에서 방의 갯수는 최소 6개에서 최대 39,320개 까지 있고 (우리집 방 한개…ㅠㅠ) median_income은 손을 댄 관계로 1~15까지 밖에 없다. 이러한 숫자들을 조정하는 방법에는 크게 두가지가 있다.\n¶(1) Min Max Scaling - Normalization (정규화)\n정규화 = (값 - 최소값) / (최대값 - 최소값)\n값을 다 0 ~ 1 사이로 바꿔 버리는 것이다. 여기에서는 MinMaxScaler()를 쓴다.\n¶(2) Standardization (표준화)\n표준화 = (값 - 평균) / 표준편차\n정규화랑은 다르게, 정해진 값의 범위가 없다. 이는 outlier에게 덜 영향을 받는 다는 장점이 있다. 여기에서는 StandardScaler를 쓴다.\n암튼 이런 transforamation 스텝을 순서에 맞게 거쳐서 이쁜 값을 만드는 것이 중요할 것이다. 이를 위해서 PipeLine 클래스를 사용할 것이다.\nPipeline의 fit을 부르면, 안에 tuple로 있는 모든 메소드들의 fit_transform()을 순차저긍로 호출하게 된다. 마지막까지 다 하게 되면, 마지막에는 fit()을 호출하고 끝낸다.\n123456789101112131415from sklearn.pipeline import Pipelinefrom sklearn.preprocessing import StandardScaler# Pipeline, 여러가지 transforamation을 엮는 데 효과적.# 이름 / estimator 로 구성되어 있음.# 마지막 estimator를 제외 하고 모두 transformers여야 함. (즉, fit_transform() 메소드가 필요함)# 순서대로 fit_transform()을 실행하다가, 마지막에는 fit()을 실행함.num_pipeline = Pipeline([        ('imputer', Imputer(strategy=\"median\")), # 빈 값을 중간 값으로 채워주고        ('attribs_adder', CombinedAttributesAdder()), # 위에서 만든 속성 추가 클래스를 활용하고        ('std_scaler', StandardScaler()), # 값을 모두 표준화 시킨다.    ])num_pipeline.fit_transform(housing_num)\n12345678910111213array([[-1.15604281,  0.77194962,  0.74333089, ..., -0.31205452,        -0.08649871,  0.15531753],       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.21768338,        -0.03353391, -0.83628902],       [ 1.18684903, -1.34218285,  0.18664186, ..., -0.46531516,        -0.09240499,  0.4222004 ],       ...,       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.3469342 ,        -0.03055414, -0.52177644],       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.02499488,         0.06150916, -0.30340741],       [-1.43579109,  0.99645926,  1.85670895, ..., -0.22852947,        -0.09586294,  0.10180567]])\n이제 숫자 컬럼만 뽑아는 class 도 만들어보자.\n12345678# attributes로 주어진 컬럼만 dataframe으로 추출해서 만들어냄class DataFrameSelector(BaseEstimator, TransformerMixin):    def __init__(self, attribute_names):        self.attribute_names = attribute_names    def fit(self, X, y=None):        return self    def transform(self, X):        return X[self.attribute_names].values\n123456789101112from sklearn.pipeline import Pipelinefrom sklearn.preprocessing import StandardScalernum_attribs = list(housing_num)cat_Attribs = [\"ocean_proximity\"]num_pipeline = Pipeline([    ('selector', DataFrameSelector(num_attribs)), # 숫자있는 컬럼만 추출    ('imputer', Imputer(strategy='median')), # 빈 값에 대해 중간값으로 채움    ('attribs_adder', CombinedAttributesAdder()), # 여러가지 속성을 더 추가    ('std_scaler', StandardScaler()) # 값들에 대해서 최종적으로 표준화])\n텍스트를 카테고리로 처리하기 위한 pipeline\n123456from sklearn.preprocessing import OneHotEncodercat_pipeline = Pipeline([    ('selector', DataFrameSelector(cat_Attribs)),    ('cat_pipeline', OneHotEncoder())])\n그리고 이것들을 다 합치자.\n123from sklearn.pipeline import FeatureUnionfull_pipeline = FeatureUnion(transformer_list=[(\"num_pipeline\", num_pipeline), (\"cat_pipeline\", cat_pipeline)])\n적용\n123housing_prepared = full_pipeline.fit_transform(housing)housing_prepared.shapehousing_prepared.data\n123(16512, 16)array([-1.15604281,  0.77194962,  0.74333089, ..., -0.09586294,        0.10180567,  1.        ])\n¶4. 모델 선택하고 훈련 시키기\n1234from sklearn.linear_model import LinearRegressionlin_reg = LinearRegression()lin_reg.fit(housing_prepared, housing_labels)\n일단 빠르게 비교하기 위해 일부 데이터만 가지고 해보자.\n1234567# let's try the full pipeline on a few training instancessome_data = housing.iloc[:5]some_labels = housing_labels.iloc[:5]some_data_prepared = full_pipeline.transform(some_data)print(\"Predictions:\", lin_reg.predict(some_data_prepared))print(\"Labels:\", list(some_labels))\n123Predictions: [210644.6046718  317768.80715244 210956.43323562  59218.98852743 189747.55850878]Labels:      [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\nMean Squared Error (MSE)를 구해봅시다.\n123456from sklearn.metrics import mean_squared_errorhousing_predictions = lin_reg.predict(housing_prepared)lin_mse = mean_squared_error(housing_labels, housing_predictions)lin_rmse = np.sqrt(lin_mse)lin_rmse\n168628.19819848923\nmedian_housing_values가 120,000~265,000 인걸 감안했을때, 68628은 너무나 큰 값이다. 굉장히 underfit한 상태임을 알 수 있다.\n이번엔 DecsionTreeRegressor를 활용해보자. 이 모델은 linear하지 않은 데이터 들 사이에 상관관계를 찾을 때 유용하다. 여기 에서 자세하게 공부해 볼 수 있다.\n12345678910# 디시전 트리를 사용해보자. from sklearn.tree import DecisionTreeRegressortree_reg = DecisionTreeRegressor()tree_reg.fit(housing_prepared, housing_labels)housing_predictions = tree_reg.predict(housing_prepared)tree_mse = mean_squared_error(housing_labels, housing_predictions)tree_rmse = np.sqrt(tree_mse)tree_rmse\n10\n에러가 전혀 없다고 나온다. 이건 좀 아니지 않나요?\n¶5. Cross-Validation으로 evlautaion을 향상 시키기\ntraining set을 training set과 validation set으로 일정비율로 나누어, 테스트해보자. 이방식 중 하나 가 K-fold cross-validation이라고 하는데, 일정한 비율로 랜덤하게 n회 누어서, 반복해서 테스트 하는 방법이다.\n12345678# 트레이닝셋을 벨리데이션 셋으로 또 나눠서 10번 cross-validation을 해보자.# K-fold cross validation# 트레이닝셋을 10개로 나눠서, 디시젼 트리 모델을 각각 10번 테스트 해보는 것이다. from sklearn.model_selection import cross_val_scorescores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)tree_rmse_scores  = np.sqrt(-scores)tree_rmse_scores\n10번 돌린 결과가 나왔다.\n123array([68226.82910941, 67439.68375039, 70350.36780248, 68827.53048332,       69029.59842291, 75828.55054539, 70465.73078927, 71469.01269653,       76190.79186194, 69329.49606677])\n123456def display_scores(scores):    print(\"Scores:\", scores)    print(\"Mean:\", scores.mean())    print(\"Standard derivation:\", scores.std())display_scores(tree_rmse_scores)\n12345Scores: [68226.82910941 67439.68375039 70350.36780248 68827.53048332 69029.59842291 75828.55054539 70465.73078927 71469.01269653 76190.79186194 69329.49606677]Mean: 70715.75915284026Standard derivation: 2865.9683978538446\n디시전 트리를 활용한결과, 그다지 좋아보이지 않는다. Linear Model보다 구려보이기까지 하다. Cross-Validation은 단순히 모델을 평가하는 것 뿐만 예측치가 얼마나 정확한지 제공 (정규분표) 한다.\n1234lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,                              scoring='neg_mean_squared_error', cv=10)lin_rmse_scores = np.sqrt(-lin_scores)display_scores(lin_rmse_scores)\n12345Scores: [66782.73844323 66960.1179304  70347.95241464 74739.57053231 68031.13387784 71193.84183403 64969.63055912 68281.61137905 71552.91570804 67665.10081912]Mean: 69052.46134977776Standard derivation: 2731.6740174446295\nLeaner Model이 조금더 나은 걸 확인할 수 있다.\n이번에는 RandomForestRegressor를 활용해보려고 한다. 랜덤 포레스트라고 불리우는 이방식은, 일종의 앙상블 학습 방법으로, 훈련 과정에서 구성한 다수의 의사결정 트리로 부터 분류 또는 평균를 출력함으로서 작동한다. 정확성도 높고, 간편하고 빠르게 학습을 하는 등 다양한 장점이 있지만 너무 느리다 ㅠ.ㅠ\n12345678910# 마지막으로 해볼 것은 RandomForestRegressor# 디시젼 트리를 랜덤하게 여러개 피처를 만들어서 테스트 하는 방식from sklearn.ensemble import RandomForestRegressorforest_reg = RandomForestRegressor()forest_reg.fit(housing_prepared, housing_labels)scores = cross_val_score(forest_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)forest_rmse_scores  = np.sqrt(-scores)display_scores(forest_rmse_scores)\n12345Scores: [52997.4173118  50186.47321364 53029.31828865 54414.07187827 52394.46338811 56393.90724324 51383.83051346 50054.41972395 55828.51540902 51771.1262269 ]Mean: 52845.35431970437Standard derivation: 2058.1934731131732\n표준 편차가 조금더 줄어들었지만, 아직도 만족스러운 결과라 할 수는 없다.\n¶참고: 모델을 파일로 떨구는 방법\n123from sklearn.externals import joblibjoblib.dump(forest_reg, \"forest_reg_model.pkl\")saved_model = joblib.load(\"forest_reg_model.pkl\")\n¶6. 모델 튜닝하기\n¶Grid Search\n좋은 결과를 만들어내는 하이퍼파리미터의 조합을 찾을 때 까지 찾는 것을 의미한다.\n12345678910111213141516171819202122## 모델 튜닝하기#  hyperparameter를 만져서 좋은 모델 만들어보기from sklearn.model_selection import GridSearchCV# 첫번째: n_estimator 3개 * max_features 4개 로 총 12가지 의 조합으로 하이퍼 파라미터로 평가함# 두번째: 2 *3 개 총 6가지 조합으로 테스트 해봄.# 총 18가지 조합으로 RandomForestRegressor를 실행. # 그리고 cv=5, 즉 Five-fold test를 하므로 총 90가지의 경우의 트레이닝을 고려하게됨.param_grid = [    &#123;'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]&#125;,    &#123;'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]&#125;]forest_reg = RandomForestRegressor()grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')grid_search.fit(housing_prepared, housing_labels)grid_search.best_params_grid_search.best_estimator_\nparam_grid를 통해 Scikit-learn은 첫번째로 12가지 의 조합(3 * 4)을, 두번째에는 6가지의 조합(2*3)을 활용하여 총 18가지의 방법으로 Grid Search를 진행했다. 그리고 이 모델을 cv(Cross-validation)을 5번씩 해서 총 90번의 연산이 돌아가게 된다.\n1234567&#123;&apos;max_features&apos;: 8, &apos;n_estimators&apos;: 30&#125;RandomForestRegressor(bootstrap=True, criterion=&apos;mse&apos;, max_depth=None,           max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,           min_impurity_split=None, min_samples_leaf=1,           min_samples_split=2, min_weight_fraction_leaf=0.0,           n_estimators=30, n_jobs=None, oob_score=False,           random_state=None, verbose=0, warm_start=False)\n123cvres = grid_search.cv_results_for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):    print(np.sqrt(-mean_score), params)\n12345678910111213141516171863620.795837027006 &#123;&apos;max_features&apos;: 2, &apos;n_estimators&apos;: 3&#125;55548.92569283444 &#123;&apos;max_features&apos;: 2, &apos;n_estimators&apos;: 10&#125;53050.85861795343 &#123;&apos;max_features&apos;: 2, &apos;n_estimators&apos;: 30&#125;59815.23943111992 &#123;&apos;max_features&apos;: 4, &apos;n_estimators&apos;: 3&#125;52773.64511880433 &#123;&apos;max_features&apos;: 4, &apos;n_estimators&apos;: 10&#125;50671.92650291877 &#123;&apos;max_features&apos;: 4, &apos;n_estimators&apos;: 30&#125;59985.840862213074 &#123;&apos;max_features&apos;: 6, &apos;n_estimators&apos;: 3&#125;52228.35440259691 &#123;&apos;max_features&apos;: 6, &apos;n_estimators&apos;: 10&#125;50217.90441108211 &#123;&apos;max_features&apos;: 6, &apos;n_estimators&apos;: 30&#125;59089.278039491895 &#123;&apos;max_features&apos;: 8, &apos;n_estimators&apos;: 3&#125;51630.326121947954 &#123;&apos;max_features&apos;: 8, &apos;n_estimators&apos;: 10&#125;50199.124440913874 &#123;&apos;max_features&apos;: 8, &apos;n_estimators&apos;: 30&#125;62217.97955428267 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 2, &apos;n_estimators&apos;: 3&#125;53866.30814960368 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 2, &apos;n_estimators&apos;: 10&#125;60700.922958303796 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 3, &apos;n_estimators&apos;: 3&#125;52858.54368577 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 3, &apos;n_estimators&apos;: 10&#125;58618.59314938758 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 4, &apos;n_estimators&apos;: 3&#125;51672.291663087286 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 4, &apos;n_estimators&apos;: 10&#125;\nRMSE가 제일 작은 50199.124440913874 {‘max_features’: 8, ‘n_estimators’: 30} 가 최적의 모델인 것으로 나타났다.\n¶Randomize Search\n앞선 그리드 서치의 경우, 조합의 수가 적을 경우에는 유용한 방법이다. 하지만 조합이 너무 많아 지는 경우, 검색이 엄청나게 오래 걸리게 될 것이다. 이 경우에는 RandomizedSearchCV를 대신 활용한다. 이는 GirdSearchCV와 굉장히 유사한 방법이지만, 모든 조합을 다 때려 박아보는 대신 랜덤하게 하이퍼파라미터에 값을 설정하여 탐색하는 방법이다. 이 방법은 일단 컴퓨팅 자원을 상대적으로 아낄 수 있다는게 가장 큰 장점이다. 그리고 만약 1000회 시도 한다고 가정했을 때, 매 회차마다 1000개의 서로 다른 하이퍼 파라미터를 사용할 수 있다는 장점도 있다. (그리드 서치였다면, 단 몇개의 제한적인 값만 사용했을 것이다)\n¶Esemble Method\n다른 방법으로는 좋은 결과를 내고 있는 모델들을 짬뽕시키는 것이다.\n¶7. 최적의 모델과 에러를 분석하기\n12feature_importances = grid_search.best_estimator_.feature_importances_feature_importances\n1234array([7.25174043e-02, 6.40038155e-02, 4.30423521e-02, 1.50651260e-02,       1.41694078e-02, 1.55005328e-02, 1.36335231e-02, 3.85814812e-01,       4.51628522e-02, 1.08855596e-01, 4.37230361e-02, 5.91899634e-03,       1.65641423e-01, 1.29954352e-04, 2.35727395e-03, 4.46389467e-03])\n각 속성별 중요도를 알아봅시다,\n12345extra_attribs = ['rooms_per_hhold', 'pop_per_hhold', 'bedrooms_per_room']cat_encoder = cat_pipeline.named_steps['cat_pipeline']cat_hone_hot_attribs = list(cat_encoder.categories_[0])attributes = num_attribs + extra_attribs + cat_hone_hot_attribssorted(zip(feature_importances, attributes), reverse=True)\n12345678910111213141516[(0.3858148117438145, &apos;median_income&apos;), (0.16564142348730257, &apos;INLAND&apos;), (0.10885559563684136, &apos;pop_per_hhold&apos;), (0.07251740425030011, &apos;longitude&apos;), (0.06400381547849927, &apos;latitude&apos;), (0.045162852166503266, &apos;rooms_per_hhold&apos;), (0.04372303606477461, &apos;bedrooms_per_room&apos;), (0.043042352127968635, &apos;housing_median_age&apos;), (0.015500532784205033, &apos;population&apos;), (0.015065126043213665, &apos;total_rooms&apos;), (0.014169407785424392, &apos;total_bedrooms&apos;), (0.01363352312072851, &apos;households&apos;), (0.005918996335933865, &apos;&lt;1H OCEAN&apos;), (0.004463894670505644, &apos;NEAR OCEAN&apos;), (0.0023572739519965376, &apos;NEAR BAY&apos;), (0.00012995435198802713, &apos;ISLAND&apos;)]\n중요도를 나열해보고, 여기애서 별 영향이 없는 변수 (ocean_proximity에서는 INLAND가 아니면 다 별 의미가 없어보인다.) 를 제거하는 방법도 사용할 수 있겠다.\n¶8. 최종적으로 예측하기\n123456789101112final_model = grid_search.best_estimator_X_test = strat_test_set.drop(\"median_house_value\", axis=1)y_test = strat_test_set['median_house_value'].copy()X_test_prepared = full_pipeline.transform(X_test)final_prediction = final_model.predict(X_test_prepared)final_mse = mean_squared_error(y_test, final_prediction)final_rmse = np.sqrt(final_mse)final_rmse\n168139.43891327262","dateCreated":"2018-11-08T00:00:00+09:00","dateModified":"2018-11-08T19:44:01+09:00","datePublished":"2018-11-08T00:00:00+09:00","description":"California Housing 데이터를 바탕으로 scikt-learn을 활용한 머신러닝 예제.\n\n¶1. 기본적인 데이터 로딩\n프록시 환경이라, 프록시를 핸들러에 추가하였습니다.\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\nimport os\nimport tarfile\nfrom six.moves import urllib\nimport numpy as np\nimport pandas as pd\n\n# 데이터 로딩\nHOUSIN","headline":"Step by Step machine laerning - 01","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.yceffort.kr/2018/11/08/step-by-step-machine-learnig-01/"},"publisher":{"@type":"Organization","name":"yceffort","sameAs":["https://github.com/yceffort","mailto: root@yceffort.kr"],"image":"https://www.gravatar.com/avatar/f24f66c6311c477d8ac26a9ef346560c","logo":{"@type":"ImageObject","url":"https://www.gravatar.com/avatar/f24f66c6311c477d8ac26a9ef346560c"}},"url":"https://www.yceffort.kr/2018/11/08/step-by-step-machine-learnig-01/","keywords":"machine-learning, scikit-learn"}</script>
    <meta name="description" content="California Housing 데이터를 바탕으로 scikt-learn을 활용한 머신러닝 예제.  ¶1. 기본적인 데이터 로딩 프록시 환경이라, 프록시를 핸들러에 추가하였습니다.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32   import os">
<meta name="keywords" content="machine-learning,scikit-learn">
<meta property="og:type" content="blog">
<meta property="og:title" content="Step by Step machine laerning - 01">
<meta property="og:url" content="https://www.yceffort.kr/2018/11/08/step-by-step-machine-learnig-01/index.html">
<meta property="og:site_name" content="yceffort">
<meta property="og:description" content="California Housing 데이터를 바탕으로 scikt-learn을 활용한 머신러닝 예제.  ¶1. 기본적인 데이터 로딩 프록시 환경이라, 프록시를 핸들러에 추가하였습니다.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32   import os">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://www.yceffort.kr/images/2018/11/ml-1-1.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2018/11/ml-1-2.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2018/11/ml-1-3.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2018/11/ml-1-4.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2018/11/ml-1-5.png">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/800px-Correlation_examples2.svg.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2018/11/ml-1-6.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2018/11/ml-1-7.png">
<meta property="og:updated_time" content="2018-11-08T10:44:01.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Step by Step machine laerning - 01">
<meta name="twitter:description" content="California Housing 데이터를 바탕으로 scikt-learn을 활용한 머신러닝 예제.  ¶1. 기본적인 데이터 로딩 프록시 환경이라, 프록시를 핸들러에 추가하였습니다.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32   import os">
<meta name="twitter:image" content="https://www.yceffort.kr/images/2018/11/ml-1-1.png">
    
    
    
    
    
    <meta property="og:image" content="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=640" />
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/style-je9ne2wwvtssbupojm9va0xqtluc5xk9hlyjdqt05wwldmrgscrkdxxcibuq.min.css">
    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-139493546-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-139493546-1');
    </script>


    
</head>
    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
    

<header id="header" data-behavior="2">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/ ">yceffort</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
            <img class="header-picture" src="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=90" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->


    

<nav id="sidebar" data-behavior="2">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a href="/#about">
                    <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=110" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">yceffort</h4>
                
                    <h5 class="sidebar-profile-bio"><p>yceffort</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/ "
                            
                            title="Home"
                        >
                    
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-tags"
                            
                            title="Tags"
                        >
                    
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link open-algolia-search"
                             href="#search"
                            
                            title="Search"
                        >
                    
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Search</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/bookmark"
                            
                            title="Bookmark"
                        >
                    
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Bookmark</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="#about"
                            
                            title="About"
                        >
                    
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/yceffort" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto: root@yceffort.kr" target="_blank" rel="noopener" title="Mail">
                    
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/atom.xml"
                            
                            title="RSS"
                        >
                    
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="2"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            Step by Step machine laerning - 01
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2018-11-08T00:00:00+09:00">
	
		    Nov 08, 2018
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>California Housing 데이터를 바탕으로 scikt-learn을 활용한 머신러닝 예제.</p>
<h2 id="1-기본적인-데이터-로딩"><a class="header-anchor" href="#1-기본적인-데이터-로딩">¶</a>1. 기본적인 데이터 로딩</h2>
<p>프록시 환경이라, 프록시를 핸들러에 추가하였습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 로딩</span></span><br><span class="line">HOUSING_PATH = os.path.join(<span class="string">"datasets"</span>, <span class="string">"housing"</span>)</span><br><span class="line">HOUSING_URL = <span class="string">"http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.tgz"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetching_housing_data</span><span class="params">(housing_url=HOUSING_URL, housing_path=HOUSING_PATH)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(housing_path):</span><br><span class="line">        os.makedirs(housing_path)</span><br><span class="line">        </span><br><span class="line">    proxy = urllib.request.ProxyHandler(&#123;<span class="string">'http'</span>: <span class="string">'http://proxy.url'</span>, <span class="string">'https'</span>:<span class="string">'http://proxy.url'</span>&#125;)</span><br><span class="line">    opener = urllib.request.build_opener(proxy)</span><br><span class="line">    urllib.request.install_opener(opener)</span><br><span class="line"></span><br><span class="line">    tgz_path = os.path.join(housing_path, <span class="string">"housing.tgz"</span>)</span><br><span class="line">    urllib.request.urlretrieve(housing_url, tgz_path)</span><br><span class="line">    housing_tgz = tarfile.open(tgz_path)</span><br><span class="line">    housing_tgz.extractall(path=housing_path)</span><br><span class="line">    housing_tgz.close()</span><br><span class="line"></span><br><span class="line">fetching_housing_data()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_housing_data</span><span class="params">(housing_path=HOUSING_PATH)</span>:</span></span><br><span class="line">    csv_path = os.path.join(housing_path, <span class="string">"housing.csv"</span>)</span><br><span class="line">    <span class="keyword">return</span> pd.read_csv(csv_path)</span><br><span class="line"></span><br><span class="line">housing = load_housing_data()</span><br><span class="line">housing.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-122.23</td>
      <td>37.88</td>
      <td>41.0</td>
      <td>880.0</td>
      <td>129.0</td>
      <td>322.0</td>
      <td>126.0</td>
      <td>8.3252</td>
      <td>452600.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-122.22</td>
      <td>37.86</td>
      <td>21.0</td>
      <td>7099.0</td>
      <td>1106.0</td>
      <td>2401.0</td>
      <td>1138.0</td>
      <td>8.3014</td>
      <td>358500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-122.24</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1467.0</td>
      <td>190.0</td>
      <td>496.0</td>
      <td>177.0</td>
      <td>7.2574</td>
      <td>352100.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1274.0</td>
      <td>235.0</td>
      <td>558.0</td>
      <td>219.0</td>
      <td>5.6431</td>
      <td>341300.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1627.0</td>
      <td>280.0</td>
      <td>565.0</td>
      <td>259.0</td>
      <td>3.8462</td>
      <td>342200.0</td>
      <td>NEAR BAY</td>
    </tr>
  </tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing.info()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;</span><br><span class="line">RangeIndex: 20640 entries, 0 to 20639</span><br><span class="line">Data columns (total 10 columns):</span><br><span class="line">longitude             20640 non-null float64</span><br><span class="line">latitude              20640 non-null float64</span><br><span class="line">housing_median_age    20640 non-null float64</span><br><span class="line">total_rooms           20640 non-null float64</span><br><span class="line">total_bedrooms        20433 non-null float64</span><br><span class="line">population            20640 non-null float64</span><br><span class="line">households            20640 non-null float64</span><br><span class="line">median_income         20640 non-null float64</span><br><span class="line">median_house_value    20640 non-null float64</span><br><span class="line">ocean_proximity       20640 non-null object</span><br><span class="line">dtypes: float64(9), object(1)</span><br><span class="line">memory usage: 1.6+ MB</span><br></pre></td></tr></table></figure>
<p><code>ocean_proximity</code>는 텍스트로 정보가 들어가 있는 것 같다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing[<span class="string">'ocean_proximity'</span>].value_counts()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;1H OCEAN     9136</span><br><span class="line">INLAND        6551</span><br><span class="line">NEAR OCEAN    2658</span><br><span class="line">NEAR BAY      2290</span><br><span class="line">ISLAND           5</span><br><span class="line">Name: ocean_proximity, dtype: int64</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing.describe()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20433.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-119.569704</td>
      <td>35.631861</td>
      <td>28.639486</td>
      <td>2635.763081</td>
      <td>537.870553</td>
      <td>1425.476744</td>
      <td>499.539680</td>
      <td>3.870671</td>
      <td>206855.816909</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.003532</td>
      <td>2.135952</td>
      <td>12.585558</td>
      <td>2181.615252</td>
      <td>421.385070</td>
      <td>1132.462122</td>
      <td>382.329753</td>
      <td>1.899822</td>
      <td>115395.615874</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-124.350000</td>
      <td>32.540000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>0.499900</td>
      <td>14999.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-121.800000</td>
      <td>33.930000</td>
      <td>18.000000</td>
      <td>1447.750000</td>
      <td>296.000000</td>
      <td>787.000000</td>
      <td>280.000000</td>
      <td>2.563400</td>
      <td>119600.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-118.490000</td>
      <td>34.260000</td>
      <td>29.000000</td>
      <td>2127.000000</td>
      <td>435.000000</td>
      <td>1166.000000</td>
      <td>409.000000</td>
      <td>3.534800</td>
      <td>179700.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>-118.010000</td>
      <td>37.710000</td>
      <td>37.000000</td>
      <td>3148.000000</td>
      <td>647.000000</td>
      <td>1725.000000</td>
      <td>605.000000</td>
      <td>4.743250</td>
      <td>264725.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>-114.310000</td>
      <td>41.950000</td>
      <td>52.000000</td>
      <td>39320.000000</td>
      <td>6445.000000</td>
      <td>35682.000000</td>
      <td>6082.000000</td>
      <td>15.000100</td>
      <td>500001.000000</td>
    </tr>
  </tbody>
</table>
<p>그래프로 보자</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># bins는 막대의 두께, figsize는 그래프의 크기다.</span></span><br><span class="line">housing.hist(bins=<span class="number">100</span>, figsize=(<span class="number">20</span>, <span class="number">15</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/2018/11/ml-1-1.png" alt="ml-1-1.png"></p>
<h2 id="2-데이터-분석"><a class="header-anchor" href="#2-데이터-분석">¶</a>2. 데이터 분석</h2>
<p>이제 데이터를 test set과 train set으로 나눠 보자.<br>
test_size 는 말그대로 테스트의 크기이고, random_states는 random값 생성을 위한 seed 값이다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_set, test_set = train_test_split(housing, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<p>이렇게 랜덤하게 나누는 것은 데이터가 클때, 그리고 속성이 많을 때는 괜찮다. 그러나 그렇게 데이터가 많지 않으면, 샘플링을 하는 과정에서도 bias가 생길 수 있다. 만약 한국의 인구비가 6:4라면, 테스트 split을 할 때에도 6:4 로 성비가 뽑혀야 괜찮다고 할 수 있을 것이다. 이를 <code>stratified sampling</code>이라고 한다. 랜덤으로 뽑을 경우, 6:4를 보장할 수는 없을 것이다.</p>
<p>다시 예제로 돌아와서, 만약 median_income이 median_housing_prices를 예측하는데 큰 요소라고 가정을 해보자. 그러기 위해선, 위에서의 예제 처럼 다양한 median_income을 카테고리화 해서 테스트 셋을 만드는 것이 중요할 것이다. 위 그림에서 볼 수 있듯이, median_income은 값이 너무나도 다양하므로, stratum처리를 해주지 않으면 테스트 셋을 랜덤하게 뽑아 낼 때마다 값이 널뛰기를 할 것이다.</p>
<p>그래서, 1.5로 나눈다음 5보다 큰 값은 다 5로 replace 해버렸다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">housing[<span class="string">"income_cat"</span>] = np.ceil(housing[<span class="string">"median_income"</span>] / <span class="number">1.5</span>)</span><br><span class="line">housing[<span class="string">"income_cat"</span>].where(housing[<span class="string">"income_cat"</span>] &lt; <span class="number">5</span>, <span class="number">5.0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">housing[<span class="string">'income_cat'</span>].hist(bins=<span class="number">10</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/images/2018/11/ml-1-2.png" alt="ml-1-2.png"></p>
<p>이제 카테고리화 했으니, 카테고리에 다라서 균등하게 나눠보도록 합시다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 불균형한 데이터에 대해서 고르게 test, train set을 나눠준다.</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br><span class="line"></span><br><span class="line">split = StratifiedShuffleSplit(n_splits=<span class="number">1</span>, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> split.split(housing, housing[<span class="string">'income_cat'</span>]):</span><br><span class="line">    strat_train_set = housing.loc[train_index]</span><br><span class="line">    strat_test_set = housing.loc[test_index]</span><br><span class="line"></span><br><span class="line">strat_test_set[<span class="string">"income_cat"</span>].value_counts() / len(strat_test_set)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">3.0    0.350533</span><br><span class="line">2.0    0.318798</span><br><span class="line">4.0    0.176357</span><br><span class="line">5.0    0.114583</span><br><span class="line">1.0    0.039729</span><br><span class="line">Name: income_cat, dtype: float64</span><br></pre></td></tr></table></figure>
<p>얼추 그래프의 분포와 비슷한 양상을 보이고 있다. 최초의 목적은 달성헀으니, 컬럼을 드랍하자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> set_ <span class="keyword">in</span> (strat_train_set, strat_test_set):</span><br><span class="line">    set_.drop(<span class="string">"income_cat"</span>, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">housing = strat_train_set.copy()</span><br><span class="line">housing.plot(kind=<span class="string">"scatter"</span>, x=<span class="string">"longitude"</span>, y=<span class="string">"latitude"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/2018/11/ml-1-3.png" alt="ml-1-3.png"></p>
<p>투명도를 넣어서 조금더 선명하게 보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing.plot(kind=<span class="string">"scatter"</span>, x=<span class="string">"longitude"</span>, y=<span class="string">"latitude"</span>, alpha=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/2018/11/ml-1-4.png" alt="ml-1-4.png"></p>
<p>조금더 이쁘장하게 만들어보자</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">housing.plot(kind=<span class="string">"scatter"</span>, <span class="comment">#산점도</span></span><br><span class="line">             x=<span class="string">"longitude"</span>, </span><br><span class="line">             y=<span class="string">"latitude"</span>, </span><br><span class="line">             alpha=<span class="number">0.4</span>, <span class="comment">#투명도</span></span><br><span class="line">             s=housing[<span class="string">'population'</span>] / <span class="number">100</span>, <span class="comment">#나타낼 데이터</span></span><br><span class="line">             label=<span class="string">"population"</span>, <span class="comment">#라벨</span></span><br><span class="line">             figsize=(<span class="number">10</span>, <span class="number">7</span>), <span class="comment">#그래프 크기</span></span><br><span class="line">             c=<span class="string">"median_house_value"</span>, <span class="comment">#색 부여할 데이터</span></span><br><span class="line">             cmap=plt.get_cmap(<span class="string">"jet"</span>), <span class="comment">#색</span></span><br><span class="line">             colorbar = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<p><img src="/images/2018/11/ml-1-5.png" alt="ml-1-5.png"></p>
<p>correlation 매트릭스를 그려보자</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">corr_matrix = housing.corr()</span><br><span class="line">corr_matrix</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>longitude</th>
      <td>1.000000</td>
      <td>-0.924478</td>
      <td>-0.105848</td>
      <td>0.048871</td>
      <td>0.076598</td>
      <td>0.108030</td>
      <td>0.063070</td>
      <td>-0.019583</td>
      <td>-0.047432</td>
    </tr>
    <tr>
      <th>latitude</th>
      <td>-0.924478</td>
      <td>1.000000</td>
      <td>0.005766</td>
      <td>-0.039184</td>
      <td>-0.072419</td>
      <td>-0.115222</td>
      <td>-0.077647</td>
      <td>-0.075205</td>
      <td>-0.142724</td>
    </tr>
    <tr>
      <th>housing_median_age</th>
      <td>-0.105848</td>
      <td>0.005766</td>
      <td>1.000000</td>
      <td>-0.364509</td>
      <td>-0.325047</td>
      <td>-0.298710</td>
      <td>-0.306428</td>
      <td>-0.111360</td>
      <td>0.114110</td>
    </tr>
    <tr>
      <th>total_rooms</th>
      <td>0.048871</td>
      <td>-0.039184</td>
      <td>-0.364509</td>
      <td>1.000000</td>
      <td>0.929379</td>
      <td>0.855109</td>
      <td>0.918392</td>
      <td>0.200087</td>
      <td>0.135097</td>
    </tr>
    <tr>
      <th>total_bedrooms</th>
      <td>0.076598</td>
      <td>-0.072419</td>
      <td>-0.325047</td>
      <td>0.929379</td>
      <td>1.000000</td>
      <td>0.876320</td>
      <td>0.980170</td>
      <td>-0.009740</td>
      <td>0.047689</td>
    </tr>
    <tr>
      <th>population</th>
      <td>0.108030</td>
      <td>-0.115222</td>
      <td>-0.298710</td>
      <td>0.855109</td>
      <td>0.876320</td>
      <td>1.000000</td>
      <td>0.904637</td>
      <td>0.002380</td>
      <td>-0.026920</td>
    </tr>
    <tr>
      <th>households</th>
      <td>0.063070</td>
      <td>-0.077647</td>
      <td>-0.306428</td>
      <td>0.918392</td>
      <td>0.980170</td>
      <td>0.904637</td>
      <td>1.000000</td>
      <td>0.010781</td>
      <td>0.064506</td>
    </tr>
    <tr>
      <th>median_income</th>
      <td>-0.019583</td>
      <td>-0.075205</td>
      <td>-0.111360</td>
      <td>0.200087</td>
      <td>-0.009740</td>
      <td>0.002380</td>
      <td>0.010781</td>
      <td>1.000000</td>
      <td>0.687160</td>
    </tr>
    <tr>
      <th>median_house_value</th>
      <td>-0.047432</td>
      <td>-0.142724</td>
      <td>0.114110</td>
      <td>0.135097</td>
      <td>0.047689</td>
      <td>-0.026920</td>
      <td>0.064506</td>
      <td>0.687160</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1에 가까울 수록 긍정적으로 강한 관계가 있음.</span></span><br><span class="line"><span class="comment"># -1에 가까울 수록 부정적으로 관계가 있음.</span></span><br><span class="line">corr_matrix[<span class="string">"median_house_value"</span>].sort_values(ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>값은 ~1 부터 1 사이의 값을 가지며, 1에 가까울 수록 강한 positive 상관관계를, -1에 가까울 수록 강한 negative 상관관계를 갖는다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">median_house_value    1.000000</span><br><span class="line">median_income         0.687160</span><br><span class="line">total_rooms           0.135097</span><br><span class="line">housing_median_age    0.114110</span><br><span class="line">households            0.064506</span><br><span class="line">total_bedrooms        0.047689</span><br><span class="line">population           -0.026920</span><br><span class="line">longitude            -0.047432</span><br><span class="line">latitude             -0.142724</span><br><span class="line">Name: median_house_value, dtype: float64</span><br></pre></td></tr></table></figure>
<p>0에 가까울 수록 아무런 관계가 없다는 것이다.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/800px-Correlation_examples2.svg.png" alt="correlation-and-dependence"></p>
<p>상관관계가 있을 수록, plot이 우/좌상향 분포를 나타낸다. 과연 그런지 봅시다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.plotting <span class="keyword">import</span> scatter_matrix</span><br><span class="line"></span><br><span class="line">attributes = [<span class="string">'median_house_value'</span>, <span class="string">'median_income'</span>, <span class="string">'total_rooms'</span>, <span class="string">'housing_median_age'</span>]</span><br><span class="line">scatter_matrix(housing[attributes], figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/images/2018/11/ml-1-6.png" alt="ml-1-6.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing.plot(kind=<span class="string">"scatter"</span>, x=<span class="string">"median_income"</span>, y=<span class="string">"median_house_value"</span>, alpha=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p>median_income 과 median_house_value와 상관관계</p>
<ol>
<li>확실히 우상향 하는 분포를 띄고 있다.</li>
<li>$500,000에 가로 선이 확실하게 보이는데, 이는 $450,000 과 $350,000에서도 뚜렷하게 보이고 있다.</li>
</ol>
<p><img src="/images/2018/11/ml-1-7.png" alt="ml-1-7.png"></p>
<p>추가적으로, 몇가지 속성 값을 만들어보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">housing[<span class="string">"rooms_per_household"</span>] = housing[<span class="string">"total_rooms"</span>] / housing[<span class="string">"households"</span>]</span><br><span class="line">housing[<span class="string">"bedrooms_per_room"</span>] = housing[<span class="string">"total_bedrooms"</span>] / housing[<span class="string">"total_rooms"</span>]</span><br><span class="line">housing[<span class="string">"population_per_household"</span>] = housing[<span class="string">"population"</span>] / housing[<span class="string">"households"</span>]</span><br><span class="line"></span><br><span class="line">corr_matrix = housing.corr()</span><br><span class="line">corr_matrix[<span class="string">'median_house_value'</span>].sort_values(ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">median_house_value          1.000000</span><br><span class="line">median_income               0.687160</span><br><span class="line">rooms_per_household         0.146285</span><br><span class="line">total_rooms                 0.135097</span><br><span class="line">housing_median_age          0.114110</span><br><span class="line">households                  0.064506</span><br><span class="line">total_bedrooms              0.047689</span><br><span class="line">population_per_household   -0.021985</span><br><span class="line">population                 -0.026920</span><br><span class="line">longitude                  -0.047432</span><br><span class="line">latitude                   -0.142724</span><br><span class="line">bedrooms_per_room          -0.259984</span><br><span class="line">Name: median_house_value, dtype: float64</span><br></pre></td></tr></table></figure>
<h2 id="3-머신러닝-알고리즘-활용을-위한-데이터-준비"><a class="header-anchor" href="#3-머신러닝-알고리즘-활용을-위한-데이터-준비">¶</a>3. 머신러닝 알고리즘 활용을 위한  데이터 준비</h2>
<h3 id="1-데이터-클리닝"><a class="header-anchor" href="#1-데이터-클리닝">¶</a>1) 데이터 클리닝</h3>
<p>일단, <code>total_bedrooms</code> 컬럼에 빈값들이 있는 것을 확인했다. 이 컬럼을 드랍하던지, 아니면 빈값을 적절하게 채우는 방법 이 있다. 빈값을 적절히 채우기 위해서는, 중간값(median)을 활용하는 것이 좋겠다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line">imputer = Imputer(strategy=<span class="string">"median"</span>)</span><br></pre></td></tr></table></figure>
<p><code>median</code>은 오로지 숫자 값만 처리할 수 있으므로, 숫자가 아닌 컬럼은 제거할 필요가 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing_num = housing.drop(<span class="string">"ocean_proximity"</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>그리고 imputer를 적용해보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">imputer.fit(housing_num)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 밑에 두개는 같은 결과를 보여준다.</span></span><br><span class="line">imputer.statistics_</span><br><span class="line">housing_num.median().values</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,</span><br><span class="line">        408.    ,    3.5409])</span><br></pre></td></tr></table></figure>
<p>imputer한 값을 다시 dataframe으로 가져오자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = imputer.transform(housing_num)</span><br><span class="line">housing_str = pd.DataFrame(x, columns=housing_num.columns)</span><br><span class="line">housing_str.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-121.89</td>
      <td>37.29</td>
      <td>38.0</td>
      <td>1568.0</td>
      <td>351.0</td>
      <td>710.0</td>
      <td>339.0</td>
      <td>2.7042</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-121.93</td>
      <td>37.05</td>
      <td>14.0</td>
      <td>679.0</td>
      <td>108.0</td>
      <td>306.0</td>
      <td>113.0</td>
      <td>6.4214</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-117.20</td>
      <td>32.77</td>
      <td>31.0</td>
      <td>1952.0</td>
      <td>471.0</td>
      <td>936.0</td>
      <td>462.0</td>
      <td>2.8621</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-119.61</td>
      <td>36.31</td>
      <td>25.0</td>
      <td>1847.0</td>
      <td>371.0</td>
      <td>1460.0</td>
      <td>353.0</td>
      <td>1.8839</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-118.59</td>
      <td>34.23</td>
      <td>17.0</td>
      <td>6592.0</td>
      <td>1525.0</td>
      <td>4459.0</td>
      <td>1463.0</td>
      <td>3.0347</td>
    </tr>
  </tbody>
</table>
<h3 id="2-텍스트와-카테고리-데이터-다루기"><a class="header-anchor" href="#2-텍스트와-카테고리-데이터-다루기">¶</a>2) 텍스트와 카테고리 데이터 다루기</h3>
<p><code>ocean_proximity</code>는 우리가 문자여서 못썼다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">housing_cat = housing[<span class="string">'ocean_proximity'</span>]</span><br><span class="line">housing_cat.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">17606     &lt;1H OCEAN</span><br><span class="line">18632     &lt;1H OCEAN</span><br><span class="line">14650    NEAR OCEAN</span><br><span class="line">3230         INLAND</span><br><span class="line">3555      &lt;1H OCEAN</span><br><span class="line">19480        INLAND</span><br><span class="line">8879      &lt;1H OCEAN</span><br><span class="line">13685        INLAND</span><br><span class="line">4937      &lt;1H OCEAN</span><br><span class="line">4861      &lt;1H OCEAN</span><br><span class="line">Name: ocean_proximity, dtype: object</span><br></pre></td></tr></table></figure>
<p>이렇게 하면 카테고리로 만들어 버릴 수 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">housing_cat_encoded, housing_categories = housing_cat.factorize()</span><br><span class="line">housing_cat_encoded[:<span class="number">10</span>]</span><br><span class="line">housing_categories</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([0, 0, 1, 2, 0, 2, 0, 2, 0, 0])</span><br><span class="line">Index([&apos;&lt;1H OCEAN&apos;, &apos;NEAR OCEAN&apos;, &apos;INLAND&apos;, &apos;NEAR BAY&apos;, &apos;ISLAND&apos;], dtype=&apos;object&apos;)</span><br></pre></td></tr></table></figure>
<p>너의 text 적당한 number로 카테고리 되었다. Korean 불만있어요?</p>
<p>근데 이렇게 한다면, 0과 1을 비슷한 값으로, 0과 4를 안비슷한 값으로 판단해버릴 것이다. 사실 숫자에는 별의미가 없기 때문에 저런일이 발생해서는 안된다. 그래서 사용하는 것이 <code>one-hot encoding</code>이다. <code>one hot endoing</code>은 이런 카테고리 데이터를 벡터화 하는 것이다. <a href="https://brunch.co.kr/@sokoban/8" target="_blank" rel="noopener">여기</a>에 잘 정리 되어 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line">encoder = OneHotEncoder()</span><br><span class="line"></span><br><span class="line"><span class="comment"># housing_cat_encoded는 횡방향으로 데이터를 길게 늘어뜨려 놓았다.</span></span><br><span class="line"><span class="comment"># 데이터 프레임과 마찬가지 형식으로 종방향으로 데이터를 바꾸기 위해 reshape를 하였다.</span></span><br><span class="line"></span><br><span class="line">housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">housing_cat_1hot.toarray()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">array([[1., 0., 0., 0., 0.],</span><br><span class="line">       [1., 0., 0., 0., 0.],</span><br><span class="line">       [0., 1., 0., 0., 0.],</span><br><span class="line">       ...,</span><br><span class="line">       [0., 0., 1., 0., 0.],</span><br><span class="line">       [1., 0., 0., 0., 0.],</span><br><span class="line">       [0., 0., 0., 1., 0.]])</span><br></pre></td></tr></table></figure>
<h3 id="3-커스텀-트랜스포머-만들기"><a class="header-anchor" href="#3-커스텀-트랜스포머-만들기">¶</a>3) 커스텀 트랜스포머 만들기</h3>
<p>이제 이 과정을 데이터가 들어올 때 마다 일일히 할 수 없는 노릇이므로, 이를 자동화하는 과정을 만들어 보려고 한다. scikit-learn에서는 이러한 데이터 클린업 과정을 자동화 할 수 있는 Class를 만들 수 있다. 이를 위한 클래스에서 필요한 것은 <code>fit()</code>, (무조건 <code>return self</code>), <code>transform()</code>, <code>fit_transform()</code>이 세가지 메소드를 구현해야 한다. 그리고 이를 위해서는 <code>TransformerMixin</code>클래스를 더해야 한다. 추가로 <code>BaseEstimator</code>를 더하면,<code>get_params()</code>와 <code>set_params()</code>메소드도 구현할 수 있는데, 이는 <a href="https://en.wikipedia.org/wiki/Hyperparameter" target="_blank" rel="noopener">hyperparameter</a>를 튜닝할  때 유용하게 사용할 수 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.base <span class="keyword">import</span> BaseEstimator, TransformerMixin</span><br><span class="line"></span><br><span class="line">rooms_ix, bedrooms_ix, population_ix, household_ix = <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># TransformerMixin Custom Cleanup Operation을 하기 위한 필수요소</span></span><br><span class="line"><span class="comment"># 필수로 구현해야 하는 것</span></span><br><span class="line"><span class="comment"># fit (return self)</span></span><br><span class="line"><span class="comment"># transform () </span></span><br><span class="line"><span class="comment"># fit_transform ()</span></span><br><span class="line"><span class="comment"># BaseEstimator 는 (*args, **kargs)룰 피할 수 있으며</span></span><br><span class="line"><span class="comment"># 두가지 method를 추가로 구현 가능, get_params(), set_params()</span></span><br><span class="line"><span class="comment"># automatic hyperparameter tuning을 하는데 유용하다고함..</span></span><br><span class="line"><span class="comment"># 아래예제에서는 add_bedrooms_per_room가 hyperparameter이며, 이 속성을 추가할지 여부를 결정할 수 있음.</span></span><br><span class="line"><span class="comment"># 가변적으로 추가해야할 파라미터들이 있을 때 유용할 것으로 보임.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CombinedAttributesAdder</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, add_bedrooms_per_room = True)</span>:</span> <span class="comment"># no *args or **kargs</span></span><br><span class="line">        self.add_bedrooms_per_room = add_bedrooms_per_room</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self  <span class="comment"># nothing else to do</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="comment"># 가정당 방의 갯수를 구한다.</span></span><br><span class="line">        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]</span><br><span class="line">        <span class="comment"># 가정당 인구 수를 구한다.</span></span><br><span class="line">        population_per_household = X[:, population_ix] / X[:, household_ix]</span><br><span class="line">        <span class="comment"># add_bedroooms_per_room (이것이 hyperparameter다!!) 이 true면</span></span><br><span class="line">        <span class="keyword">if</span> self.add_bedrooms_per_room:</span><br><span class="line">            <span class="comment"># 방당 침실 수도 구한다.</span></span><br><span class="line">            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]</span><br><span class="line">            <span class="comment"># 다 하나의 array로 합혀 준다.</span></span><br><span class="line">            <span class="keyword">return</span> np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> np.c_[X, rooms_per_household, population_per_household]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 위에서 만든걸 선언한다.</span></span><br><span class="line">attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 이를 바탕으로 housing의 값을 변경한다.</span></span><br><span class="line">housing_extra_attribs = attr_adder.transform(housing.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 새로 생긴 값을 추가해서 housing을 만든다.</span></span><br><span class="line">housing_extra_attribs = pd.DataFrame(housing_extra_attribs, columns=list(housing.columns)+[<span class="string">"rooms_per_household"</span>, <span class="string">"population_per_household"</span>])</span><br><span class="line">housing_extra_attribs.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>ocean_proximity</th>
      <th>rooms_per_household</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-121.89</td>
      <td>37.29</td>
      <td>38</td>
      <td>1568</td>
      <td>351</td>
      <td>710</td>
      <td>339</td>
      <td>2.7042</td>
      <td>&lt;1H OCEAN</td>
      <td>4.62537</td>
      <td>2.0944</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-121.93</td>
      <td>37.05</td>
      <td>14</td>
      <td>679</td>
      <td>108</td>
      <td>306</td>
      <td>113</td>
      <td>6.4214</td>
      <td>&lt;1H OCEAN</td>
      <td>6.00885</td>
      <td>2.70796</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-117.2</td>
      <td>32.77</td>
      <td>31</td>
      <td>1952</td>
      <td>471</td>
      <td>936</td>
      <td>462</td>
      <td>2.8621</td>
      <td>NEAR OCEAN</td>
      <td>4.22511</td>
      <td>2.02597</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-119.61</td>
      <td>36.31</td>
      <td>25</td>
      <td>1847</td>
      <td>371</td>
      <td>1460</td>
      <td>353</td>
      <td>1.8839</td>
      <td>INLAND</td>
      <td>5.23229</td>
      <td>4.13598</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-118.59</td>
      <td>34.23</td>
      <td>17</td>
      <td>6592</td>
      <td>1525</td>
      <td>4459</td>
      <td>1463</td>
      <td>3.0347</td>
      <td>&lt;1H OCEAN</td>
      <td>4.50581</td>
      <td>3.04785</td>
    </tr>
  </tbody>
</table>
<h2 id="4-모델-적용하기"><a class="header-anchor" href="#4-모델-적용하기">¶</a>4. 모델 적용하기</h2>
<p>머신러닝을 할 때 중요한 것은 데이터 보정이다. 이 데이터에서 방의 갯수는 최소 6개에서 최대 39,320개 까지 있고 (우리집 방 한개…ㅠㅠ) median_income은 손을 댄 관계로 1~15까지 밖에 없다. 이러한 숫자들을 조정하는 방법에는 크게 두가지가 있다.</p>
<h4 id="1-min-max-scaling-normalization-정규화"><a class="header-anchor" href="#1-min-max-scaling-normalization-정규화">¶</a>(1) Min Max Scaling - Normalization (정규화)</h4>
<p>정규화 = (값 - 최소값) / (최대값 - 최소값)</p>
<p>값을 다 0 ~ 1 사이로 바꿔 버리는 것이다. 여기에서는 <code>MinMaxScaler()</code>를 쓴다.</p>
<h4 id="2-standardization-표준화"><a class="header-anchor" href="#2-standardization-표준화">¶</a>(2) Standardization (표준화)</h4>
<p>표준화 = (값 - 평균) / 표준편차</p>
<p>정규화랑은 다르게, 정해진 값의 범위가 없다. 이는 outlier에게 덜 영향을 받는 다는 장점이 있다. 여기에서는 <code>StandardScaler</code>를 쓴다.</p>
<p>암튼 이런 transforamation 스텝을 순서에 맞게 거쳐서 이쁜 값을 만드는 것이 중요할 것이다. 이를 위해서 <code>PipeLine</code> 클래스를 사용할 것이다.</p>
<p><code>Pipeline</code>의 <code>fit</code>을 부르면, 안에 tuple로 있는 모든 메소드들의 <code>fit_transform()</code>을 순차저긍로 호출하게 된다. 마지막까지 다 하게 되면, 마지막에는 <code>fit()</code>을 호출하고 끝낸다.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pipeline, 여러가지 transforamation을 엮는 데 효과적.</span></span><br><span class="line"><span class="comment"># 이름 / estimator 로 구성되어 있음.</span></span><br><span class="line"><span class="comment"># 마지막 estimator를 제외 하고 모두 transformers여야 함. (즉, fit_transform() 메소드가 필요함)</span></span><br><span class="line"><span class="comment"># 순서대로 fit_transform()을 실행하다가, 마지막에는 fit()을 실행함.</span></span><br><span class="line"></span><br><span class="line">num_pipeline = Pipeline([</span><br><span class="line">        (<span class="string">'imputer'</span>, Imputer(strategy=<span class="string">"median"</span>)), <span class="comment"># 빈 값을 중간 값으로 채워주고</span></span><br><span class="line">        (<span class="string">'attribs_adder'</span>, CombinedAttributesAdder()), <span class="comment"># 위에서 만든 속성 추가 클래스를 활용하고</span></span><br><span class="line">        (<span class="string">'std_scaler'</span>, StandardScaler()), <span class="comment"># 값을 모두 표준화 시킨다.</span></span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">num_pipeline.fit_transform(housing_num)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">array([[-1.15604281,  0.77194962,  0.74333089, ..., -0.31205452,</span><br><span class="line">        -0.08649871,  0.15531753],</span><br><span class="line">       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.21768338,</span><br><span class="line">        -0.03353391, -0.83628902],</span><br><span class="line">       [ 1.18684903, -1.34218285,  0.18664186, ..., -0.46531516,</span><br><span class="line">        -0.09240499,  0.4222004 ],</span><br><span class="line">       ...,</span><br><span class="line">       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.3469342 ,</span><br><span class="line">        -0.03055414, -0.52177644],</span><br><span class="line">       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.02499488,</span><br><span class="line">         0.06150916, -0.30340741],</span><br><span class="line">       [-1.43579109,  0.99645926,  1.85670895, ..., -0.22852947,</span><br><span class="line">        -0.09586294,  0.10180567]])</span><br></pre></td></tr></table></figure>
<p>이제 숫자 컬럼만 뽑아는 class 도 만들어보자.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># attributes로 주어진 컬럼만 dataframe으로 추출해서 만들어냄</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataFrameSelector</span><span class="params">(BaseEstimator, TransformerMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, attribute_names)</span>:</span></span><br><span class="line">        self.attribute_names = attribute_names</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y=None)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> X[self.attribute_names].values</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">num_attribs = list(housing_num)</span><br><span class="line">cat_Attribs = [<span class="string">"ocean_proximity"</span>]</span><br><span class="line"></span><br><span class="line">num_pipeline = Pipeline([</span><br><span class="line">    (<span class="string">'selector'</span>, DataFrameSelector(num_attribs)), <span class="comment"># 숫자있는 컬럼만 추출</span></span><br><span class="line">    (<span class="string">'imputer'</span>, Imputer(strategy=<span class="string">'median'</span>)), <span class="comment"># 빈 값에 대해 중간값으로 채움</span></span><br><span class="line">    (<span class="string">'attribs_adder'</span>, CombinedAttributesAdder()), <span class="comment"># 여러가지 속성을 더 추가</span></span><br><span class="line">    (<span class="string">'std_scaler'</span>, StandardScaler()) <span class="comment"># 값들에 대해서 최종적으로 표준화</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>텍스트를 카테고리로 처리하기 위한 pipeline</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line">cat_pipeline = Pipeline([</span><br><span class="line">    (<span class="string">'selector'</span>, DataFrameSelector(cat_Attribs)),</span><br><span class="line">    (<span class="string">'cat_pipeline'</span>, OneHotEncoder())</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>그리고 이것들을 다 합치자.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> FeatureUnion</span><br><span class="line"></span><br><span class="line">full_pipeline = FeatureUnion(transformer_list=[(<span class="string">"num_pipeline"</span>, num_pipeline), (<span class="string">"cat_pipeline"</span>, cat_pipeline)])</span><br></pre></td></tr></table></figure>
<p>적용</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">housing_prepared = full_pipeline.fit_transform(housing)</span><br><span class="line">housing_prepared.shape</span><br><span class="line">housing_prepared.data</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(16512, 16)</span><br><span class="line">array([-1.15604281,  0.77194962,  0.74333089, ..., -0.09586294,</span><br><span class="line">        0.10180567,  1.        ])</span><br></pre></td></tr></table></figure>
<h3 id="4-모델-선택하고-훈련-시키기"><a class="header-anchor" href="#4-모델-선택하고-훈련-시키기">¶</a>4. 모델 선택하고 훈련 시키기</h3>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(housing_prepared, housing_labels)</span><br></pre></td></tr></table></figure>
<p>일단 빠르게 비교하기 위해 일부 데이터만 가지고 해보자.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># let's try the full pipeline on a few training instances</span></span><br><span class="line">some_data = housing.iloc[:<span class="number">5</span>]</span><br><span class="line">some_labels = housing_labels.iloc[:<span class="number">5</span>]</span><br><span class="line">some_data_prepared = full_pipeline.transform(some_data)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Predictions:"</span>, lin_reg.predict(some_data_prepared))</span><br><span class="line">print(<span class="string">"Labels:"</span>, list(some_labels))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Predictions: [210644.6046718  317768.80715244 210956.43323562  59218.98852743</span><br><span class="line"> 189747.55850878]</span><br><span class="line">Labels:      [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]</span><br></pre></td></tr></table></figure>
<p>Mean Squared Error (MSE)를 구해봅시다.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line">housing_predictions = lin_reg.predict(housing_prepared)</span><br><span class="line">lin_mse = mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line">lin_rmse = np.sqrt(lin_mse)</span><br><span class="line">lin_rmse</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">68628.19819848923</span><br></pre></td></tr></table></figure>
<p>median_housing_values가 120,000~265,000 인걸 감안했을때, 68628은 너무나 큰 값이다. 굉장히 underfit한 상태임을 알 수 있다.</p>
<p>이번엔 <code>DecsionTreeRegressor</code>를 활용해보자. 이 모델은 linear하지 않은 데이터 들 사이에 상관관계를 찾을 때 유용하다. <a href="https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95" target="_blank" rel="noopener">여기</a> 에서 자세하게 공부해 볼 수 있다.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 디시전 트리를 사용해보자. </span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line">tree_reg = DecisionTreeRegressor()</span><br><span class="line">tree_reg.fit(housing_prepared, housing_labels)</span><br><span class="line"></span><br><span class="line">housing_predictions = tree_reg.predict(housing_prepared)</span><br><span class="line">tree_mse = mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line">tree_rmse = np.sqrt(tree_mse)</span><br><span class="line">tree_rmse</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0</span><br></pre></td></tr></table></figure>
<p>에러가 전혀 없다고 나온다. 이건 좀 아니지 않나요?</p>
<h2 id="5-cross-validation으로-evlautaion을-향상-시키기"><a class="header-anchor" href="#5-cross-validation으로-evlautaion을-향상-시키기">¶</a>5. Cross-Validation으로 evlautaion을 향상 시키기</h2>
<p>training set을 training set과 validation set으로 일정비율로 나누어, 테스트해보자. 이방식 중 하나 가 <code>K-fold cross-validation</code>이라고 하는데, 일정한 비율로 랜덤하게 n회 누어서, 반복해서 테스트 하는 방법이다.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 트레이닝셋을 벨리데이션 셋으로 또 나눠서 10번 cross-validation을 해보자.</span></span><br><span class="line"><span class="comment"># K-fold cross validation</span></span><br><span class="line"><span class="comment"># 트레이닝셋을 10개로 나눠서, 디시젼 트리 모델을 각각 10번 테스트 해보는 것이다. </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring=<span class="string">"neg_mean_squared_error"</span>, cv=<span class="number">10</span>)</span><br><span class="line">tree_rmse_scores  = np.sqrt(-scores)</span><br><span class="line">tree_rmse_scores</span><br></pre></td></tr></table></figure>
<p>10번 돌린 결과가 나왔다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([68226.82910941, 67439.68375039, 70350.36780248, 68827.53048332,</span><br><span class="line">       69029.59842291, 75828.55054539, 70465.73078927, 71469.01269653,</span><br><span class="line">       76190.79186194, 69329.49606677])</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">display_scores</span><span class="params">(scores)</span>:</span></span><br><span class="line">    print(<span class="string">"Scores:"</span>, scores)</span><br><span class="line">    print(<span class="string">"Mean:"</span>, scores.mean())</span><br><span class="line">    print(<span class="string">"Standard derivation:"</span>, scores.std())</span><br><span class="line"></span><br><span class="line">display_scores(tree_rmse_scores)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Scores: [68226.82910941 67439.68375039 70350.36780248 68827.53048332</span><br><span class="line"> 69029.59842291 75828.55054539 70465.73078927 71469.01269653</span><br><span class="line"> 76190.79186194 69329.49606677]</span><br><span class="line">Mean: 70715.75915284026</span><br><span class="line">Standard derivation: 2865.9683978538446</span><br></pre></td></tr></table></figure>
<p>디시전 트리를 활용한결과, 그다지 좋아보이지 않는다. Linear Model보다 구려보이기까지 하다. Cross-Validation은 단순히 모델을 평가하는 것 뿐만 예측치가 얼마나 정확한지 제공 (정규분표) 한다.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, </span><br><span class="line">                             scoring=<span class="string">'neg_mean_squared_error'</span>, cv=<span class="number">10</span>)</span><br><span class="line">lin_rmse_scores = np.sqrt(-lin_scores)</span><br><span class="line">display_scores(lin_rmse_scores)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Scores: [66782.73844323 66960.1179304  70347.95241464 74739.57053231</span><br><span class="line"> 68031.13387784 71193.84183403 64969.63055912 68281.61137905</span><br><span class="line"> 71552.91570804 67665.10081912]</span><br><span class="line">Mean: 69052.46134977776</span><br><span class="line">Standard derivation: 2731.6740174446295</span><br></pre></td></tr></table></figure>
<p>Leaner Model이 조금더 나은 걸 확인할 수 있다.</p>
<p>이번에는 <code>RandomForestRegressor</code>를 활용해보려고 한다. <a href="https://ko.wikipedia.org/wiki/%EB%9E%9C%EB%8D%A4_%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8" target="_blank" rel="noopener">랜덤 포레스트</a>라고 불리우는 이방식은, 일종의 앙상블 학습 방법으로, 훈련 과정에서 구성한 다수의 의사결정 트리로 부터 분류 또는 평균를 출력함으로서 작동한다. 정확성도 높고, 간편하고 빠르게 학습을 하는 등 다양한 장점이 있지만 너무 느리다 ㅠ.ㅠ</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 마지막으로 해볼 것은 RandomForestRegressor</span></span><br><span class="line"><span class="comment"># 디시젼 트리를 랜덤하게 여러개 피처를 만들어서 테스트 하는 방식</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">forest_reg = RandomForestRegressor()</span><br><span class="line">forest_reg.fit(housing_prepared, housing_labels)</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(forest_reg, housing_prepared, housing_labels, scoring=<span class="string">"neg_mean_squared_error"</span>, cv=<span class="number">10</span>)</span><br><span class="line">forest_rmse_scores  = np.sqrt(-scores)</span><br><span class="line">display_scores(forest_rmse_scores)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Scores: [52997.4173118  50186.47321364 53029.31828865 54414.07187827</span><br><span class="line"> 52394.46338811 56393.90724324 51383.83051346 50054.41972395</span><br><span class="line"> 55828.51540902 51771.1262269 ]</span><br><span class="line">Mean: 52845.35431970437</span><br><span class="line">Standard derivation: 2058.1934731131732</span><br></pre></td></tr></table></figure>
<p>표준 편차가 조금더 줄어들었지만, 아직도 만족스러운 결과라 할 수는 없다.</p>
<h4 id="참고-모델을-파일로-떨구는-방법"><a class="header-anchor" href="#참고-모델을-파일로-떨구는-방법">¶</a>참고: 모델을 파일로 떨구는 방법</h4>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line">joblib.dump(forest_reg, <span class="string">"forest_reg_model.pkl"</span>)</span><br><span class="line">saved_model = joblib.load(<span class="string">"forest_reg_model.pkl"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="6-모델-튜닝하기"><a class="header-anchor" href="#6-모델-튜닝하기">¶</a>6. 모델 튜닝하기</h2>
<h3 id="grid-search"><a class="header-anchor" href="#grid-search">¶</a>Grid Search</h3>
<p>좋은 결과를 만들어내는 하이퍼파리미터의 조합을 찾을 때 까지 찾는 것을 의미한다.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 모델 튜닝하기</span></span><br><span class="line"><span class="comment">#  hyperparameter를 만져서 좋은 모델 만들어보기</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># 첫번째: n_estimator 3개 * max_features 4개 로 총 12가지 의 조합으로 하이퍼 파라미터로 평가함</span></span><br><span class="line"><span class="comment"># 두번째: 2 *3 개 총 6가지 조합으로 테스트 해봄.</span></span><br><span class="line"><span class="comment"># 총 18가지 조합으로 RandomForestRegressor를 실행. </span></span><br><span class="line"><span class="comment"># 그리고 cv=5, 즉 Five-fold test를 하므로 총 90가지의 경우의 트레이닝을 고려하게됨.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">param_grid = [</span><br><span class="line">    &#123;<span class="string">'n_estimators'</span>: [<span class="number">3</span>, <span class="number">10</span>, <span class="number">30</span>], <span class="string">'max_features'</span>: [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]&#125;,</span><br><span class="line">    &#123;<span class="string">'bootstrap'</span>: [<span class="literal">False</span>], <span class="string">'n_estimators'</span>: [<span class="number">3</span>, <span class="number">10</span>], <span class="string">'max_features'</span>: [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">forest_reg = RandomForestRegressor()</span><br><span class="line">grid_search = GridSearchCV(forest_reg, param_grid, cv=<span class="number">5</span>, scoring=<span class="string">'neg_mean_squared_error'</span>)</span><br><span class="line">grid_search.fit(housing_prepared, housing_labels)</span><br><span class="line"></span><br><span class="line">grid_search.best_params_</span><br><span class="line">grid_search.best_estimator_</span><br></pre></td></tr></table></figure>
<p>param_grid를 통해 Scikit-learn은 첫번째로 12가지 의 조합(3 * 4)을, 두번째에는 6가지의 조합(2*3)을 활용하여 총 18가지의 방법으로 Grid Search를 진행했다. 그리고 이 모델을 cv(Cross-validation)을 5번씩 해서 총 90번의 연산이 돌아가게 된다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;&apos;max_features&apos;: 8, &apos;n_estimators&apos;: 30&#125;</span><br><span class="line">RandomForestRegressor(bootstrap=True, criterion=&apos;mse&apos;, max_depth=None,</span><br><span class="line">           max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,</span><br><span class="line">           min_impurity_split=None, min_samples_leaf=1,</span><br><span class="line">           min_samples_split=2, min_weight_fraction_leaf=0.0,</span><br><span class="line">           n_estimators=30, n_jobs=None, oob_score=False,</span><br><span class="line">           random_state=None, verbose=0, warm_start=False)</span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cvres = grid_search.cv_results_</span><br><span class="line"><span class="keyword">for</span> mean_score, params <span class="keyword">in</span> zip(cvres[<span class="string">'mean_test_score'</span>], cvres[<span class="string">'params'</span>]):</span><br><span class="line">    print(np.sqrt(-mean_score), params)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">63620.795837027006 &#123;&apos;max_features&apos;: 2, &apos;n_estimators&apos;: 3&#125;</span><br><span class="line">55548.92569283444 &#123;&apos;max_features&apos;: 2, &apos;n_estimators&apos;: 10&#125;</span><br><span class="line">53050.85861795343 &#123;&apos;max_features&apos;: 2, &apos;n_estimators&apos;: 30&#125;</span><br><span class="line">59815.23943111992 &#123;&apos;max_features&apos;: 4, &apos;n_estimators&apos;: 3&#125;</span><br><span class="line">52773.64511880433 &#123;&apos;max_features&apos;: 4, &apos;n_estimators&apos;: 10&#125;</span><br><span class="line">50671.92650291877 &#123;&apos;max_features&apos;: 4, &apos;n_estimators&apos;: 30&#125;</span><br><span class="line">59985.840862213074 &#123;&apos;max_features&apos;: 6, &apos;n_estimators&apos;: 3&#125;</span><br><span class="line">52228.35440259691 &#123;&apos;max_features&apos;: 6, &apos;n_estimators&apos;: 10&#125;</span><br><span class="line">50217.90441108211 &#123;&apos;max_features&apos;: 6, &apos;n_estimators&apos;: 30&#125;</span><br><span class="line">59089.278039491895 &#123;&apos;max_features&apos;: 8, &apos;n_estimators&apos;: 3&#125;</span><br><span class="line">51630.326121947954 &#123;&apos;max_features&apos;: 8, &apos;n_estimators&apos;: 10&#125;</span><br><span class="line">50199.124440913874 &#123;&apos;max_features&apos;: 8, &apos;n_estimators&apos;: 30&#125;</span><br><span class="line">62217.97955428267 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 2, &apos;n_estimators&apos;: 3&#125;</span><br><span class="line">53866.30814960368 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 2, &apos;n_estimators&apos;: 10&#125;</span><br><span class="line">60700.922958303796 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 3, &apos;n_estimators&apos;: 3&#125;</span><br><span class="line">52858.54368577 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 3, &apos;n_estimators&apos;: 10&#125;</span><br><span class="line">58618.59314938758 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 4, &apos;n_estimators&apos;: 3&#125;</span><br><span class="line">51672.291663087286 &#123;&apos;bootstrap&apos;: False, &apos;max_features&apos;: 4, &apos;n_estimators&apos;: 10&#125;</span><br></pre></td></tr></table></figure>
<p>RMSE가 제일 작은 50199.124440913874 {‘max_features’: 8, ‘n_estimators’: 30} 가 최적의 모델인 것으로 나타났다.</p>
<h3 id="randomize-search"><a class="header-anchor" href="#randomize-search">¶</a>Randomize Search</h3>
<p>앞선 그리드 서치의 경우, 조합의 수가 적을 경우에는 유용한 방법이다. 하지만 조합이 너무 많아 지는 경우, 검색이 엄청나게 오래 걸리게 될 것이다. 이 경우에는 <code>RandomizedSearchCV</code>를 대신 활용한다. 이는 <code>GirdSearchCV</code>와 굉장히 유사한 방법이지만, 모든 조합을 다 때려 박아보는 대신 랜덤하게 하이퍼파라미터에 값을 설정하여 탐색하는 방법이다. 이 방법은 일단 컴퓨팅 자원을 상대적으로 아낄 수 있다는게 가장 큰 장점이다. 그리고 만약 1000회 시도 한다고 가정했을 때, 매 회차마다 1000개의 서로 다른 하이퍼 파라미터를 사용할 수 있다는 장점도 있다. (그리드 서치였다면, 단 몇개의 제한적인 값만 사용했을 것이다)</p>
<h3 id="esemble-method"><a class="header-anchor" href="#esemble-method">¶</a>Esemble Method</h3>
<p>다른 방법으로는 좋은 결과를 내고 있는 모델들을 짬뽕시키는 것이다.</p>
<h2 id="7-최적의-모델과-에러를-분석하기"><a class="header-anchor" href="#7-최적의-모델과-에러를-분석하기">¶</a>7. 최적의 모델과 에러를 분석하기</h2>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">feature_importances = grid_search.best_estimator_.feature_importances_</span><br><span class="line">feature_importances</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">array([7.25174043e-02, 6.40038155e-02, 4.30423521e-02, 1.50651260e-02,</span><br><span class="line">       1.41694078e-02, 1.55005328e-02, 1.36335231e-02, 3.85814812e-01,</span><br><span class="line">       4.51628522e-02, 1.08855596e-01, 4.37230361e-02, 5.91899634e-03,</span><br><span class="line">       1.65641423e-01, 1.29954352e-04, 2.35727395e-03, 4.46389467e-03])</span><br></pre></td></tr></table></figure>
<p>각 속성별 중요도를 알아봅시다,</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">extra_attribs = [<span class="string">'rooms_per_hhold'</span>, <span class="string">'pop_per_hhold'</span>, <span class="string">'bedrooms_per_room'</span>]</span><br><span class="line">cat_encoder = cat_pipeline.named_steps[<span class="string">'cat_pipeline'</span>]</span><br><span class="line">cat_hone_hot_attribs = list(cat_encoder.categories_[<span class="number">0</span>])</span><br><span class="line">attributes = num_attribs + extra_attribs + cat_hone_hot_attribs</span><br><span class="line">sorted(zip(feature_importances, attributes), reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[(0.3858148117438145, &apos;median_income&apos;),</span><br><span class="line"> (0.16564142348730257, &apos;INLAND&apos;),</span><br><span class="line"> (0.10885559563684136, &apos;pop_per_hhold&apos;),</span><br><span class="line"> (0.07251740425030011, &apos;longitude&apos;),</span><br><span class="line"> (0.06400381547849927, &apos;latitude&apos;),</span><br><span class="line"> (0.045162852166503266, &apos;rooms_per_hhold&apos;),</span><br><span class="line"> (0.04372303606477461, &apos;bedrooms_per_room&apos;),</span><br><span class="line"> (0.043042352127968635, &apos;housing_median_age&apos;),</span><br><span class="line"> (0.015500532784205033, &apos;population&apos;),</span><br><span class="line"> (0.015065126043213665, &apos;total_rooms&apos;),</span><br><span class="line"> (0.014169407785424392, &apos;total_bedrooms&apos;),</span><br><span class="line"> (0.01363352312072851, &apos;households&apos;),</span><br><span class="line"> (0.005918996335933865, &apos;&lt;1H OCEAN&apos;),</span><br><span class="line"> (0.004463894670505644, &apos;NEAR OCEAN&apos;),</span><br><span class="line"> (0.0023572739519965376, &apos;NEAR BAY&apos;),</span><br><span class="line"> (0.00012995435198802713, &apos;ISLAND&apos;)]</span><br></pre></td></tr></table></figure>
<p>중요도를 나열해보고, 여기애서 별 영향이 없는 변수 (<code>ocean_proximity</code>에서는 <code>INLAND</code>가 아니면 다 별 의미가 없어보인다.) 를 제거하는 방법도 사용할 수 있겠다.</p>
<h2 id="8-최종적으로-예측하기"><a class="header-anchor" href="#8-최종적으로-예측하기">¶</a>8. 최종적으로 예측하기</h2>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">final_model = grid_search.best_estimator_</span><br><span class="line"></span><br><span class="line">X_test = strat_test_set.drop(<span class="string">"median_house_value"</span>, axis=<span class="number">1</span>)</span><br><span class="line">y_test = strat_test_set[<span class="string">'median_house_value'</span>].copy()</span><br><span class="line"></span><br><span class="line">X_test_prepared = full_pipeline.transform(X_test)</span><br><span class="line"></span><br><span class="line">final_prediction = final_model.predict(X_test_prepared)</span><br><span class="line"></span><br><span class="line">final_mse = mean_squared_error(y_test, final_prediction)</span><br><span class="line">final_rmse = np.sqrt(final_mse)</span><br><span class="line">final_rmse</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">68139.43891327262</span><br></pre></td></tr></table></figure>
            

        </div>
    </div>

    <style>.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#000000 !important;background-color:#FFFFFF !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 0px 9px !important;font-size: 17px !important;letter-spacing:-0.08px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:'Lato', sans-serif !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#000000 !important;}</style><link href="https://fonts.googleapis.com/css?family=Lato&subset=latin,latin-ext" rel="stylesheet">
    <center style="display: block; text-align: -webkit-center; margin-top: 20px;">
        <a class="bmc-button" target="_blank" href="https://www.buymeacoffee.com/foryeffort"><img src="https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg" alt="coffee for yceffort"><span style="margin-left:5px">coffee for yceffort</span></a>
    </center>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-link" href="/tags/machine-learning/">machine-learning</a> <a class="tag tag--primary tag--small t-link" href="/tags/scikit-learn/">scikit-learn</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2018/11/08/three-smart-contract-misconceptions/" data-tooltip="왜 대부분의 스마트 컨트랙트 사례가 실현 불가능한가?" aria-label="PREVIOUS: 왜 대부분의 스마트 컨트랙트 사례가 실현 불가능한가?">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2018/11/07/bitcoin-and-other-cryptocurrencies-are-useless/" data-tooltip="비트코인과 다른 암호화폐는 쓸모가 없다." aria-label="NEXT: 비트코인과 다른 암호화폐는 쓸모가 없다.">
                
                    <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://www.yceffort.kr/2018/11/08/step-by-step-machine-learnig-01/" title="Share on Facebook">
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://www.yceffort.kr/2018/11/08/step-by-step-machine-learnig-01/" title="Share on Twitter">
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2019 yceffort. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="2">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2018/11/08/three-smart-contract-misconceptions/" data-tooltip="왜 대부분의 스마트 컨트랙트 사례가 실현 불가능한가?" aria-label="PREVIOUS: 왜 대부분의 스마트 컨트랙트 사례가 실현 불가능한가?">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2018/11/07/bitcoin-and-other-cryptocurrencies-are-useless/" data-tooltip="비트코인과 다른 암호화폐는 쓸모가 없다." aria-label="NEXT: 비트코인과 다른 암호화폐는 쓸모가 없다.">
                
                    <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://www.yceffort.kr/2018/11/08/step-by-step-machine-learnig-01/" title="Share on Facebook">
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://www.yceffort.kr/2018/11/08/step-by-step-machine-learnig-01/" title="Share on Twitter">
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="2">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://www.yceffort.kr/2018/11/08/step-by-step-machine-learnig-01/">
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https://www.yceffort.kr/2018/11/08/step-by-step-machine-learnig-01/">
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=110" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">yceffort</h4>
        
            <div id="about-card-bio"><p>yceffort</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>programmer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Korea
            </div>
        
    </div>
</div>

        
            <div id="algolia-search-modal" class="modal-container">
    <div class="modal">
        <div class="modal-header">
            <span class="close-button"><i class="fa fa-times"></i></span>
            <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
                <span class="searchby-algolia-text text-color-light text-small">by</span>
                <img class="searchby-algolia-logo" src="https://community.algolia.com/wordpress/img/community-badge.svg">
            </a>
            <i class="search-icon fa fa-search"></i>
            <form id="algolia-search-form">
                <input type="text" id="algolia-search-input" name="search"
                    class="form-control input--large search-input" placeholder="Search "
                    />
            </form>
        </div>
        <div class="modal-body">
            <div class="no-result text-color-light text-center">no post found</div>
            <div class="results">
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/Levenshtein-distance/">
                            <h3 class="media-heading">두 String의 유사도를 측정해보자 - Levenshtein distance</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/Reactivex-subject/">
                            <h3 class="media-heading">ReactiveX) Subject</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/bitcoin-btcd-bitcoin-cli/">
                            <h3 class="media-heading">Bitcoin) BTCD와 bitcoin-cli (bitcoin core)의 차이</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/ReactiveX-Observable/">
                            <h3 class="media-heading">ReactiveX) Observable</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/compare-string-with-voice/">
                            <h3 class="media-heading">발음 기반으로 String의 유사도를 비교해 보자.</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/i-bought-bitcoin-and/">
                            <h3 class="media-heading">Bitcoin) 비트코인 샀던 후기</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/tracking-bitcoin-core-sync/">
                            <h3 class="media-heading">Bitcoin) Bitcoin-core의 Sync를 동기화 해보자.</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/some-trick-delphi/">
                            <h3 class="media-heading">Delphi) Some tricks</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/06/01/golang-structure-embedding/">
                            <h3 class="media-heading">GoLang) 구조체와 임베딩</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Jun 1, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/06/17/bitcoin-white-paper-summary/">
                            <h3 class="media-heading">Bitcoin) 비트코인 백서 요약</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Jun 17, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
            </div>
        </div>
        <div class="modal-footer">
            <p class="results-count text-medium"
                data-message-zero="no post found"
                data-message-one="1 post found"
                data-message-other="{n} posts found">
                252 posts found
            </p>
        </div>
    </div>
</div>

        
        
<div id="cover" style="background-image:url('https://photos.smugmug.com/Galleries/All/i-m7cLXBm/0/X3/Lights%20of%20Lyngen-X3.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/script-tyo1warvoujbh4kfpbfo25ifgfxk1phrstngrnj1bltb2lvqnfrkfwvv5szv.min.js"></script>
<!--SCRIPTS END-->

    
        <script>
             var disqus_config = function () {
                 this.page.url = 'https://www.yceffort.kr/2018/11/08/step-by-step-machine-learnig-01/';
                 
                    this.page.identifier = '2018/11/08/step-by-step-machine-learnig-01/';
                 
             };
            (function() {
                var d = document, s = d.createElement('script');
                var disqus_shortname = 'https-www-yceffort-kr';
                s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
    


    <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.14.1/moment-with-locales.min.js"></script>
    <script src="//cdn.jsdelivr.net/algoliasearch/3/algoliasearch.min.js"></script>
    <script>
        var algoliaClient = algoliasearch('LA1F1N8028', 'a69ce72946da4962e0d62d5a662a0c06');
        var algoliaIndex = algoliaClient.initIndex('yceffort_blog');
    </script>


    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
