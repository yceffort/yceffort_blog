
<!DOCTYPE html>
<html lang="en">
    

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="yceffort">
    <meta name="google-site-verification" content="TRGuZGQqLhBScdz5opOQ5vD2jLwfHmWrWdze_xY0EbQ" />

    <title>Pytorch 09) - Transfer Learning - yceffort</title>
    <meta name="author" content="yceffort">
    
    <meta name="keywords" content="programming,innovation,technology,">
    
    <link rel="apple-touch-icon" sizes="57x57" href="/images/favicon/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/images/favicon/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/images/favicon/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/images/favicon/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/images/favicon/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/images/favicon/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/images/favicon/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/images/favicon/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192" href="/images/favicon/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="/images/favicon/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png">
    <link rel="manifest" href="/images/favicon/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/images/favicon/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">
    
    <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"yceffort","sameAs":["https://github.com/yceffort","mailto: root@yceffort.kr"],"image":"https://www.gravatar.com/avatar/f24f66c6311c477d8ac26a9ef346560c"},"articleBody":"Pytorch - 09) Transfer Learning\n¶Transfer Learning\n기존에 만들어진 모델을 이용하여, 새로운 모델이 조금더 빠르게 학습하고 예측을 더 높이는 방법이다.\n실질적으로, CNN을 처음부터 학습시키는 일은 많지 않다. 이 모델은 고려해야할 사항이 많고, (Layer의 숫자, 활성화함수의 종류, 기타 hyper parameter 등) 실질적으로 학습을 시키기 위해서는 엄청난 자원과 시간이 소비되기 때문이다. 그래서 기존에 학습되어 있는 모델을 바탕으로 새로운 모델을 만들어 학습하는 것을 transfer learning이라고 한다.\n¶언제 써야 하는가?\n\nLabeled 된 data 가 많지 않을 때 (학습시킬 데이터가 많지 않을 때)\n효과적으로 훈련된 모델이 이미 존재할 때\n\n¶AlexNet\n2012년 ImageNet Large Scale Visual Recognition Challenge에서 우승한 팀 논문의 첫번째 저자가 Alex 머시기 인데, 그 사람의 이름을 따서 개발한 CNN을 AlexNet이라 한다. 구조적인 관점에서는 LeNet과 크게 다르지 않지만, GPU를 사용하여 의미있는 결과를 얻었다. 이후 연구자들은 CNN구조를 설계 할 때 GPU를 고려하는 것이 유행처럼 번졌다.\n총 5개의 Convolutional Layer와 3개의 fully-connected layer로 구성되어 있으며, 맨마지막 1000개의 category분류를 위해 Softmax를 사용한다. 이렇게 만들어진 AlexNet은 65만개의 perceptron, 6000만개의 parameter와 6억 3천만개의 connection으로 구성되어 있다.\nLeNet은 32x32크기의 흑백영상이라 크기가 매우작았찌만, AlexNet은 227x227x3로 구성되어 있기 때문에, 첫번째 kernel의 크기가 11x11x3으로 크다. (stride=4) 결과적으로 96개의 필터를 생성하기 때문에 결과는 55x55x96이 된다.\n\n아무튼 위와 같은 구조다.\n¶VGG16\n\n주요 특징은 아래와 같다.\n\n입력: 224*224 크기의 고정된 RGB 이미지\n구조:\n\nConvoluitional Layer (3x3 filter, stride=1, padding=True)\nMax-Pooling Layer (2x2 filtter, stride=2)\n1x1 Conv Layer (1x1 filter, stride=1)\nFully Connected Layer (4096 &gt; 4096 &gt; 1000)\n\n\n특징:\n\n모든  레이어에 3x3 필터 적용\n1x1 Conv Layer 사용\n다섯장의 Max-Pooling Layer 사용\n\n\n\n¶코드\n123456789import torchimport matplotlib.pyplot as pltimport numpy as npimport torch.nn.functional as Ffrom torch import nnfrom torchvision import datasets, transforms, modelsmodel = models.alexnet(pretrained=True)model\n1234567891011121314151617181920212223242526AlexNet(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))    (1): ReLU(inplace)    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))    (4): ReLU(inplace)    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (7): ReLU(inplace)    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (9): ReLU(inplace)    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): ReLU(inplace)    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (classifier): Sequential(    (0): Dropout(p=0.5)    (1): Linear(in_features=9216, out_features=4096, bias=True)    (2): ReLU(inplace)    (3): Dropout(p=0.5)    (4): Linear(in_features=4096, out_features=4096, bias=True)    (5): ReLU(inplace)    (6): Linear(in_features=4096, out_features=1000, bias=True)  ))\nAlexNet의 구조가 나온다.\n12for params in model.features.parameters():  params.requires_grad = False\n여기에서 feature exrtaction부분은 이미 train 된 부분 이므로, 따로 역전파를 하는 과정에서 gradient를 계산할 필요가 없다. 따라서 위의 코드가 꼭 필요하다.\n그리고 우리가 할 것은 딱 두개, 개미와 벌을 구별하는 것이므로 https://github.com/jaddoescad/ants_and_bees.git 마지막 out을 2로 맞출 필요가 있다.\n1234567import torch.nn as nnn_inputs = model.classifier[-1].in_featureslast_layer = nn.Linear(n_inputs, len(classes))model.classifier[-1] = last_layermodel\n1234567891011121314151617181920212223242526AlexNet(  (features): Sequential(    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))    (1): ReLU(inplace)    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))    (4): ReLU(inplace)    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (7): ReLU(inplace)    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (9): ReLU(inplace)    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): ReLU(inplace)    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)  )  (classifier): Sequential(    (0): Dropout(p=0.5)    (1): Linear(in_features=9216, out_features=4096, bias=True)    (2): ReLU(inplace)    (3): Dropout(p=0.5)    (4): Linear(in_features=4096, out_features=4096, bias=True)    (5): ReLU(inplace)    (6): Linear(in_features=4096, out_features=2, bias=True)  ))\n이제 훈련시켜 보자.\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748===================================================epoch:  1training loss: 0.03956, acc: 0.573770validation loss: 0.01909, acc: 0.836601===================================================epoch:  2training loss: 0.03207, acc: 0.733607validation loss: 0.01858, acc: 0.843137===================================================epoch:  3training loss: 0.02075, acc: 0.774590validation loss: 0.01699, acc: 0.869281===================================================epoch:  4training loss: 0.02153, acc: 0.778688validation loss: 0.01905, acc: 0.862745===================================================epoch:  5training loss: 0.02300, acc: 0.774590validation loss: 0.02242, acc: 0.856209===================================================epoch:  6training loss: 0.01945, acc: 0.840164validation loss: 0.01588, acc: 0.882353===================================================epoch:  7training loss: 0.01738, acc: 0.836066validation loss: 0.01681, acc: 0.908497===================================================epoch:  8training loss: 0.01634, acc: 0.840164validation loss: 0.01626, acc: 0.888889===================================================epoch:  9training loss: 0.01587, acc: 0.844262validation loss: 0.01711, acc: 0.888889===================================================epoch:  10training loss: 0.01863, acc: 0.807377validation loss: 0.01947, acc: 0.888889===================================================epoch:  11training loss: 0.01724, acc: 0.856557validation loss: 0.01790, acc: 0.882353===================================================epoch:  12training loss: 0.01554, acc: 0.864754validation loss: 0.02125, acc: 0.869281\n\n\n데이터 자체가 작아서 그래프가 요상한 모양이지만, 데이터가 작은 것 치고도 정확하게 분류했다.\n마찬가지 방법으로 vgg16을 적용할 수 있다.\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748===================================================epoch:  1training loss: 0.02633, acc: 0.733607validation loss: 0.01347, acc: 0.901961===================================================epoch:  2training loss: 0.01908, acc: 0.856557validation loss: 0.01464, acc: 0.921569===================================================epoch:  3training loss: 0.01473, acc: 0.901639validation loss: 0.01444, acc: 0.915033===================================================epoch:  4training loss: 0.01205, acc: 0.885246validation loss: 0.01606, acc: 0.908497===================================================epoch:  5training loss: 0.00824, acc: 0.913934validation loss: 0.02344, acc: 0.901961===================================================epoch:  6training loss: 0.01456, acc: 0.864754validation loss: 0.02176, acc: 0.888889===================================================epoch:  7training loss: 0.01378, acc: 0.864754validation loss: 0.01917, acc: 0.915033===================================================epoch:  8training loss: 0.00952, acc: 0.909836validation loss: 0.02024, acc: 0.921569===================================================epoch:  9training loss: 0.00945, acc: 0.918033validation loss: 0.02147, acc: 0.901961===================================================epoch:  10training loss: 0.01164, acc: 0.918033validation loss: 0.02123, acc: 0.921569===================================================epoch:  11training loss: 0.00972, acc: 0.897541validation loss: 0.01810, acc: 0.941176===================================================epoch:  12training loss: 0.00840, acc: 0.922131validation loss: 0.03352, acc: 0.882353\nVGG16이 더 정확한 모습을 보였다.\n\n\n","dateCreated":"2019-02-26T00:00:00+09:00","dateModified":"2019-02-26T14:17:54+09:00","datePublished":"2019-02-26T00:00:00+09:00","description":"Pytorch - 09) Transfer Learning\n\n¶Transfer Learning\n기존에 만들어진 모델을 이용하여, 새로운 모델이 조금더 빠르게 학습하고 예측을 더 높이는 방법이다.\n\n실질적으로, CNN을 처음부터 학습시키는 일은 많지 않다. 이 모델은 고려해야할 사항이 많고, (Layer의 숫자, 활성화함수의 종류, 기타 hyper parameter 등) 실질적으로 학습을 시키기 위해서는 엄청난 자원과 시간이 소비되기 때문이다. 그래서 기존에 학습되어 있는 모델을 바탕으로 새로운 모델을 만들어 학습하는 것을 transf","headline":"Pytorch 09) - Transfer Learning","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.yceffort.kr/2019/02/26/pytorch-09-transfer-learning/"},"publisher":{"@type":"Organization","name":"yceffort","sameAs":["https://github.com/yceffort","mailto: root@yceffort.kr"],"image":"https://www.gravatar.com/avatar/f24f66c6311c477d8ac26a9ef346560c","logo":{"@type":"ImageObject","url":"https://www.gravatar.com/avatar/f24f66c6311c477d8ac26a9ef346560c"}},"url":"https://www.yceffort.kr/2019/02/26/pytorch-09-transfer-learning/","keywords":"pytorch"}</script>
    <meta name="description" content="Pytorch - 09) Transfer Learning  ¶Transfer Learning 기존에 만들어진 모델을 이용하여, 새로운 모델이 조금더 빠르게 학습하고 예측을 더 높이는 방법이다.  실질적으로, CNN을 처음부터 학습시키는 일은 많지 않다. 이 모델은 고려해야할 사항이 많고, (Layer의 숫자, 활성화함수의 종류, 기타 hyper parame">
<meta name="keywords" content="pytorch">
<meta property="og:type" content="blog">
<meta property="og:title" content="Pytorch 09) - Transfer Learning">
<meta property="og:url" content="https://www.yceffort.kr/2019/02/26/pytorch-09-transfer-learning/index.html">
<meta property="og:site_name" content="yceffort">
<meta property="og:description" content="Pytorch - 09) Transfer Learning  ¶Transfer Learning 기존에 만들어진 모델을 이용하여, 새로운 모델이 조금더 빠르게 학습하고 예측을 더 높이는 방법이다.  실질적으로, CNN을 처음부터 학습시키는 일은 많지 않다. 이 모델은 고려해야할 사항이 많고, (Layer의 숫자, 활성화함수의 종류, 기타 hyper parame">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://www.researchgate.net/profile/Jaime_Gallego2/publication/318168077/figure/fig1/AS:578190894927872@1514862859810/AlexNet-CNN-architecture-layers.png">
<meta property="og:image" content="https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/transfer-learning-1.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/transfer-learning-2.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/transfer-learning-4.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/transfer-learning-3.png">
<meta property="og:updated_time" content="2019-02-26T05:17:54.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pytorch 09) - Transfer Learning">
<meta name="twitter:description" content="Pytorch - 09) Transfer Learning  ¶Transfer Learning 기존에 만들어진 모델을 이용하여, 새로운 모델이 조금더 빠르게 학습하고 예측을 더 높이는 방법이다.  실질적으로, CNN을 처음부터 학습시키는 일은 많지 않다. 이 모델은 고려해야할 사항이 많고, (Layer의 숫자, 활성화함수의 종류, 기타 hyper parame">
<meta name="twitter:image" content="https://www.researchgate.net/profile/Jaime_Gallego2/publication/318168077/figure/fig1/AS:578190894927872@1514862859810/AlexNet-CNN-architecture-layers.png">
    
    
    
    
    
    <meta property="og:image" content="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=640" />
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/style-je9ne2wwvtssbupojm9va0xqtluc5xk9hlyjdqt05wwldmrgscrkdxxcibuq.min.css">
    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-139493546-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-139493546-1');
    </script>


    
</head>
    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
    

<header id="header" data-behavior="2">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/ ">yceffort</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
            <img class="header-picture" src="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=90" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->


    

<nav id="sidebar" data-behavior="2">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a href="/#about">
                    <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=110" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">yceffort</h4>
                
                    <h5 class="sidebar-profile-bio"><p>yceffort</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/ "
                            
                            title="Home"
                        >
                    
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-tags"
                            
                            title="Tags"
                        >
                    
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link open-algolia-search"
                             href="#search"
                            
                            title="Search"
                        >
                    
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Search</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/bookmark"
                            
                            title="Bookmark"
                        >
                    
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Bookmark</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="#about"
                            
                            title="About"
                        >
                    
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/yceffort" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto: root@yceffort.kr" target="_blank" rel="noopener" title="Mail">
                    
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/atom.xml"
                            
                            title="RSS"
                        >
                    
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="2"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            Pytorch 09) - Transfer Learning
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2019-02-26T00:00:00+09:00">
	
		    Feb 26, 2019
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>Pytorch - 09) Transfer Learning</p>
<h2 id="transfer-learning"><a class="header-anchor" href="#transfer-learning">¶</a>Transfer Learning</h2>
<p>기존에 만들어진 모델을 이용하여, 새로운 모델이 조금더 빠르게 학습하고 예측을 더 높이는 방법이다.</p>
<p>실질적으로, CNN을 처음부터 학습시키는 일은 많지 않다. 이 모델은 고려해야할 사항이 많고, (Layer의 숫자, 활성화함수의 종류, 기타 hyper parameter 등) 실질적으로 학습을 시키기 위해서는 엄청난 자원과 시간이 소비되기 때문이다. 그래서 기존에 학습되어 있는 모델을 바탕으로 새로운 모델을 만들어 학습하는 것을 transfer learning이라고 한다.</p>
<h2 id="언제-써야-하는가"><a class="header-anchor" href="#언제-써야-하는가">¶</a>언제 써야 하는가?</h2>
<ul>
<li>Labeled 된 data 가 많지 않을 때 (학습시킬 데이터가 많지 않을 때)</li>
<li>효과적으로 훈련된 모델이 이미 존재할 때</li>
</ul>
<h2 id="alexnet"><a class="header-anchor" href="#alexnet">¶</a>AlexNet</h2>
<p>2012년 ImageNet Large Scale Visual Recognition Challenge에서 우승한 팀 논문의 첫번째 저자가 Alex 머시기 인데, 그 사람의 이름을 따서 개발한 CNN을 AlexNet이라 한다. 구조적인 관점에서는 LeNet과 크게 다르지 않지만, GPU를 사용하여 의미있는 결과를 얻었다. 이후 연구자들은 CNN구조를 설계 할 때 GPU를 고려하는 것이 유행처럼 번졌다.</p>
<p>총 5개의 Convolutional Layer와 3개의 fully-connected layer로 구성되어 있으며, 맨마지막 1000개의 category분류를 위해 Softmax를 사용한다. 이렇게 만들어진 AlexNet은 65만개의 perceptron, 6000만개의 parameter와 6억 3천만개의 connection으로 구성되어 있다.</p>
<p>LeNet은 32x32크기의 흑백영상이라 크기가 매우작았찌만, AlexNet은 227x227x3로 구성되어 있기 때문에, 첫번째 kernel의 크기가 11x11x3으로 크다. (stride=4) 결과적으로 96개의 필터를 생성하기 때문에 결과는 55x55x96이 된다.</p>
<p><img src="https://www.researchgate.net/profile/Jaime_Gallego2/publication/318168077/figure/fig1/AS:578190894927872@1514862859810/AlexNet-CNN-architecture-layers.png" alt="AlexNet"></p>
<p>아무튼 위와 같은 구조다.</p>
<h2 id="vgg16"><a class="header-anchor" href="#vgg16">¶</a>VGG16</h2>
<p><img src="https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png" alt="vgg16"></p>
<p>주요 특징은 아래와 같다.</p>
<ul>
<li>입력: 224*224 크기의 고정된 RGB 이미지</li>
<li>구조:
<ul>
<li>Convoluitional Layer (3x3 filter, stride=1, padding=True)</li>
<li>Max-Pooling Layer (2x2 filtter, stride=2)</li>
<li>1x1 Conv Layer (1x1 filter, stride=1)</li>
<li>Fully Connected Layer (4096 &gt; 4096 &gt; 1000)</li>
</ul>
</li>
<li>특징:
<ul>
<li>모든  레이어에 3x3 필터 적용</li>
<li>1x1 Conv Layer 사용</li>
<li>다섯장의 Max-Pooling Layer 사용</li>
</ul>
</li>
</ul>
<h2 id="코드"><a class="header-anchor" href="#코드">¶</a>코드</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms, models</span><br><span class="line"></span><br><span class="line">model = models.alexnet(pretrained=<span class="literal">True</span>)</span><br><span class="line">model</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">AlexNet(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))</span><br><span class="line">    (1): ReLU(inplace)</span><br><span class="line">    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">    (4): ReLU(inplace)</span><br><span class="line">    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (7): ReLU(inplace)</span><br><span class="line">    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (9): ReLU(inplace)</span><br><span class="line">    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (11): ReLU(inplace)</span><br><span class="line">    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Dropout(p=0.5)</span><br><span class="line">    (1): Linear(in_features=9216, out_features=4096, bias=True)</span><br><span class="line">    (2): ReLU(inplace)</span><br><span class="line">    (3): Dropout(p=0.5)</span><br><span class="line">    (4): Linear(in_features=4096, out_features=4096, bias=True)</span><br><span class="line">    (5): ReLU(inplace)</span><br><span class="line">    (6): Linear(in_features=4096, out_features=1000, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>AlexNet의 구조가 나온다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> params <span class="keyword">in</span> model.features.parameters():</span><br><span class="line">  params.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>여기에서 feature exrtaction부분은 이미 train 된 부분 이므로, 따로 역전파를 하는 과정에서 gradient를 계산할 필요가 없다. 따라서 위의 코드가 꼭 필요하다.</p>
<p>그리고 우리가 할 것은 딱 두개, 개미와 벌을 구별하는 것이므로 <a href="https://github.com/jaddoescad/ants_and_bees.git" target="_blank" rel="noopener">https://github.com/jaddoescad/ants_and_bees.git</a> 마지막 out을 2로 맞출 필요가 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">n_inputs = model.classifier[<span class="number">-1</span>].in_features</span><br><span class="line">last_layer = nn.Linear(n_inputs, len(classes))</span><br><span class="line">model.classifier[<span class="number">-1</span>] = last_layer</span><br><span class="line"></span><br><span class="line">model</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">AlexNet(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))</span><br><span class="line">    (1): ReLU(inplace)</span><br><span class="line">    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">    (4): ReLU(inplace)</span><br><span class="line">    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (7): ReLU(inplace)</span><br><span class="line">    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (9): ReLU(inplace)</span><br><span class="line">    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">    (11): ReLU(inplace)</span><br><span class="line">    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  )</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (0): Dropout(p=0.5)</span><br><span class="line">    (1): Linear(in_features=9216, out_features=4096, bias=True)</span><br><span class="line">    (2): ReLU(inplace)</span><br><span class="line">    (3): Dropout(p=0.5)</span><br><span class="line">    (4): Linear(in_features=4096, out_features=4096, bias=True)</span><br><span class="line">    (5): ReLU(inplace)</span><br><span class="line">    (6): Linear(in_features=4096, out_features=2, bias=True)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>이제 훈련시켜 보자.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">===================================================</span><br><span class="line">epoch:  1</span><br><span class="line">training loss: 0.03956, acc: 0.573770</span><br><span class="line">validation loss: 0.01909, acc: 0.836601</span><br><span class="line">===================================================</span><br><span class="line">epoch:  2</span><br><span class="line">training loss: 0.03207, acc: 0.733607</span><br><span class="line">validation loss: 0.01858, acc: 0.843137</span><br><span class="line">===================================================</span><br><span class="line">epoch:  3</span><br><span class="line">training loss: 0.02075, acc: 0.774590</span><br><span class="line">validation loss: 0.01699, acc: 0.869281</span><br><span class="line">===================================================</span><br><span class="line">epoch:  4</span><br><span class="line">training loss: 0.02153, acc: 0.778688</span><br><span class="line">validation loss: 0.01905, acc: 0.862745</span><br><span class="line">===================================================</span><br><span class="line">epoch:  5</span><br><span class="line">training loss: 0.02300, acc: 0.774590</span><br><span class="line">validation loss: 0.02242, acc: 0.856209</span><br><span class="line">===================================================</span><br><span class="line">epoch:  6</span><br><span class="line">training loss: 0.01945, acc: 0.840164</span><br><span class="line">validation loss: 0.01588, acc: 0.882353</span><br><span class="line">===================================================</span><br><span class="line">epoch:  7</span><br><span class="line">training loss: 0.01738, acc: 0.836066</span><br><span class="line">validation loss: 0.01681, acc: 0.908497</span><br><span class="line">===================================================</span><br><span class="line">epoch:  8</span><br><span class="line">training loss: 0.01634, acc: 0.840164</span><br><span class="line">validation loss: 0.01626, acc: 0.888889</span><br><span class="line">===================================================</span><br><span class="line">epoch:  9</span><br><span class="line">training loss: 0.01587, acc: 0.844262</span><br><span class="line">validation loss: 0.01711, acc: 0.888889</span><br><span class="line">===================================================</span><br><span class="line">epoch:  10</span><br><span class="line">training loss: 0.01863, acc: 0.807377</span><br><span class="line">validation loss: 0.01947, acc: 0.888889</span><br><span class="line">===================================================</span><br><span class="line">epoch:  11</span><br><span class="line">training loss: 0.01724, acc: 0.856557</span><br><span class="line">validation loss: 0.01790, acc: 0.882353</span><br><span class="line">===================================================</span><br><span class="line">epoch:  12</span><br><span class="line">training loss: 0.01554, acc: 0.864754</span><br><span class="line">validation loss: 0.02125, acc: 0.869281</span><br></pre></td></tr></table></figure>
<p><img src="/images/2019/02/transfer-learning-1.png" alt="transfer-learning-1"></p>
<p><img src="/images/2019/02/transfer-learning-2.png" alt="transfer-learning-2"></p>
<p>데이터 자체가 작아서 그래프가 요상한 모양이지만, 데이터가 작은 것 치고도 정확하게 분류했다.</p>
<p>마찬가지 방법으로 vgg16을 적용할 수 있다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">===================================================</span><br><span class="line">epoch:  1</span><br><span class="line">training loss: 0.02633, acc: 0.733607</span><br><span class="line">validation loss: 0.01347, acc: 0.901961</span><br><span class="line">===================================================</span><br><span class="line">epoch:  2</span><br><span class="line">training loss: 0.01908, acc: 0.856557</span><br><span class="line">validation loss: 0.01464, acc: 0.921569</span><br><span class="line">===================================================</span><br><span class="line">epoch:  3</span><br><span class="line">training loss: 0.01473, acc: 0.901639</span><br><span class="line">validation loss: 0.01444, acc: 0.915033</span><br><span class="line">===================================================</span><br><span class="line">epoch:  4</span><br><span class="line">training loss: 0.01205, acc: 0.885246</span><br><span class="line">validation loss: 0.01606, acc: 0.908497</span><br><span class="line">===================================================</span><br><span class="line">epoch:  5</span><br><span class="line">training loss: 0.00824, acc: 0.913934</span><br><span class="line">validation loss: 0.02344, acc: 0.901961</span><br><span class="line">===================================================</span><br><span class="line">epoch:  6</span><br><span class="line">training loss: 0.01456, acc: 0.864754</span><br><span class="line">validation loss: 0.02176, acc: 0.888889</span><br><span class="line">===================================================</span><br><span class="line">epoch:  7</span><br><span class="line">training loss: 0.01378, acc: 0.864754</span><br><span class="line">validation loss: 0.01917, acc: 0.915033</span><br><span class="line">===================================================</span><br><span class="line">epoch:  8</span><br><span class="line">training loss: 0.00952, acc: 0.909836</span><br><span class="line">validation loss: 0.02024, acc: 0.921569</span><br><span class="line">===================================================</span><br><span class="line">epoch:  9</span><br><span class="line">training loss: 0.00945, acc: 0.918033</span><br><span class="line">validation loss: 0.02147, acc: 0.901961</span><br><span class="line">===================================================</span><br><span class="line">epoch:  10</span><br><span class="line">training loss: 0.01164, acc: 0.918033</span><br><span class="line">validation loss: 0.02123, acc: 0.921569</span><br><span class="line">===================================================</span><br><span class="line">epoch:  11</span><br><span class="line">training loss: 0.00972, acc: 0.897541</span><br><span class="line">validation loss: 0.01810, acc: 0.941176</span><br><span class="line">===================================================</span><br><span class="line">epoch:  12</span><br><span class="line">training loss: 0.00840, acc: 0.922131</span><br><span class="line">validation loss: 0.03352, acc: 0.882353</span><br></pre></td></tr></table></figure>
<p>VGG16이 더 정확한 모습을 보였다.</p>
<p><img src="/images/2019/02/transfer-learning-4.png" alt="transfer-learning-4"></p>
<p><img src="/images/2019/02/transfer-learning-3.png" alt="transfer-learning-3"></p>

            

        </div>
    </div>

    <style>.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#000000 !important;background-color:#FFFFFF !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 0px 9px !important;font-size: 17px !important;letter-spacing:-0.08px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:'Lato', sans-serif !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#000000 !important;}</style><link href="https://fonts.googleapis.com/css?family=Lato&subset=latin,latin-ext" rel="stylesheet">
    <center style="display: block; text-align: -webkit-center; margin-top: 20px;">
        <a class="bmc-button" target="_blank" href="https://www.buymeacoffee.com/foryeffort"><img src="https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg" alt="coffee for yceffort"><span style="margin-left:5px">coffee for yceffort</span></a>
    </center>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-link" href="/tags/pytorch/">pytorch</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2019/03/05/deep-learning-2-activation-function/" data-tooltip="Deep Learning 02) - Activation Function" aria-label="PREVIOUS: Deep Learning 02) - Activation Function">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2019/02/25/pytorch-08-CIFAR-10/" data-tooltip="Pytorch 08) - CIFAR 10 학습" aria-label="NEXT: Pytorch 08) - CIFAR 10 학습">
                
                    <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://www.yceffort.kr/2019/02/26/pytorch-09-transfer-learning/" title="Share on Facebook">
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://www.yceffort.kr/2019/02/26/pytorch-09-transfer-learning/" title="Share on Twitter">
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2019 yceffort. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="2">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2019/03/05/deep-learning-2-activation-function/" data-tooltip="Deep Learning 02) - Activation Function" aria-label="PREVIOUS: Deep Learning 02) - Activation Function">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2019/02/25/pytorch-08-CIFAR-10/" data-tooltip="Pytorch 08) - CIFAR 10 학습" aria-label="NEXT: Pytorch 08) - CIFAR 10 학습">
                
                    <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://www.yceffort.kr/2019/02/26/pytorch-09-transfer-learning/" title="Share on Facebook">
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://www.yceffort.kr/2019/02/26/pytorch-09-transfer-learning/" title="Share on Twitter">
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="2">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://www.yceffort.kr/2019/02/26/pytorch-09-transfer-learning/">
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https://www.yceffort.kr/2019/02/26/pytorch-09-transfer-learning/">
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=110" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">yceffort</h4>
        
            <div id="about-card-bio"><p>yceffort</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>programmer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Korea
            </div>
        
    </div>
</div>

        
            <div id="algolia-search-modal" class="modal-container">
    <div class="modal">
        <div class="modal-header">
            <span class="close-button"><i class="fa fa-times"></i></span>
            <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
                <span class="searchby-algolia-text text-color-light text-small">by</span>
                <img class="searchby-algolia-logo" src="https://community.algolia.com/wordpress/img/community-badge.svg">
            </a>
            <i class="search-icon fa fa-search"></i>
            <form id="algolia-search-form">
                <input type="text" id="algolia-search-input" name="search"
                    class="form-control input--large search-input" placeholder="Search "
                    />
            </form>
        </div>
        <div class="modal-body">
            <div class="no-result text-color-light text-center">no post found</div>
            <div class="results">
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/Levenshtein-distance/">
                            <h3 class="media-heading">두 String의 유사도를 측정해보자 - Levenshtein distance</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/Reactivex-subject/">
                            <h3 class="media-heading">ReactiveX) Subject</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/bitcoin-btcd-bitcoin-cli/">
                            <h3 class="media-heading">Bitcoin) BTCD와 bitcoin-cli (bitcoin core)의 차이</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/ReactiveX-Observable/">
                            <h3 class="media-heading">ReactiveX) Observable</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/compare-string-with-voice/">
                            <h3 class="media-heading">발음 기반으로 String의 유사도를 비교해 보자.</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/i-bought-bitcoin-and/">
                            <h3 class="media-heading">Bitcoin) 비트코인 샀던 후기</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/tracking-bitcoin-core-sync/">
                            <h3 class="media-heading">Bitcoin) Bitcoin-core의 Sync를 동기화 해보자.</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/some-trick-delphi/">
                            <h3 class="media-heading">Delphi) Some tricks</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/06/01/golang-structure-embedding/">
                            <h3 class="media-heading">GoLang) 구조체와 임베딩</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Jun 1, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/06/17/bitcoin-white-paper-summary/">
                            <h3 class="media-heading">Bitcoin) 비트코인 백서 요약</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Jun 17, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
            </div>
        </div>
        <div class="modal-footer">
            <p class="results-count text-medium"
                data-message-zero="no post found"
                data-message-one="1 post found"
                data-message-other="{n} posts found">
                252 posts found
            </p>
        </div>
    </div>
</div>

        
        
<div id="cover" style="background-image:url('https://photos.smugmug.com/Galleries/All/i-m7cLXBm/0/X3/Lights%20of%20Lyngen-X3.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/script-tyo1warvoujbh4kfpbfo25ifgfxk1phrstngrnj1bltb2lvqnfrkfwvv5szv.min.js"></script>
<!--SCRIPTS END-->

    
        <script>
             var disqus_config = function () {
                 this.page.url = 'https://www.yceffort.kr/2019/02/26/pytorch-09-transfer-learning/';
                 
                    this.page.identifier = '2019/02/26/pytorch-09-transfer-learning/';
                 
             };
            (function() {
                var d = document, s = d.createElement('script');
                var disqus_shortname = 'https-www-yceffort-kr';
                s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
    


    <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.14.1/moment-with-locales.min.js"></script>
    <script src="//cdn.jsdelivr.net/algoliasearch/3/algoliasearch.min.js"></script>
    <script>
        var algoliaClient = algoliasearch('LA1F1N8028', 'a69ce72946da4962e0d62d5a662a0c06');
        var algoliaIndex = algoliaClient.initIndex('yceffort_blog');
    </script>


    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
