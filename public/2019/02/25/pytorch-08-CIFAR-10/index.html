
<!DOCTYPE html>
<html lang="en">
    

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="yceffort">
    <meta name="google-site-verification" content="TRGuZGQqLhBScdz5opOQ5vD2jLwfHmWrWdze_xY0EbQ" />

    <title>Pytorch 08) - CIFAR 10 학습 - yceffort</title>
    <meta name="author" content="yceffort">
    
    <meta name="keywords" content="programming,innovation,technology,">
    
    <link rel="apple-touch-icon" sizes="57x57" href="/images/favicon/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/images/favicon/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/images/favicon/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/images/favicon/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/images/favicon/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/images/favicon/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/images/favicon/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/images/favicon/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192" href="/images/favicon/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96" href="/images/favicon/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png">
    <link rel="manifest" href="/images/favicon/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="/images/favicon/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">
    
    <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"yceffort","sameAs":["https://github.com/yceffort","mailto: root@yceffort.kr"],"image":"https://www.gravatar.com/avatar/f24f66c6311c477d8ac26a9ef346560c"},"articleBody":"Pytorch - 08) CIFAR 10\nCIFAR 10 는 열가지 단어별 이미지가 있는 데이터 셋이다. 기존에 손글씨를 분류하는 것 보다는 확실히 어려운 작업이 될 것이다.\n\n¶전처리 작업\n1234567891011121314151617181920212223242526272829303132333435363738import torchimport matplotlib.pyplot as pltimport numpy as npfrom torch import nnfrom torch.nn import functional as Ffrom torchvision import datasets, transformstransformer = transforms.Compose([transforms.Resize((32, 32)),                                  transforms.ToTensor(),                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                 ])training_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transformer)validation_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transformer)training_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=100, shuffle=True)validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100, shuffle=False)def im_convert(tensor):  image = tensor.clone().detach().numpy()  image = image.transpose(1, 2, 0)  image = image * np.array([0.5, 0.5, 0.5] + np.array([0.5, 0.5, 0.5]))  image = image.clip(0, 1)  return imageclasses = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")dataiter = iter(training_loader)images, labels = dataiter.next()fig = plt.figure(figsize=(25, 4))for i in np.arange(20):  # row 2 column 10  ax = fig.add_subplot(2, 10, i+1, xticks=[], yticks=[])  plt.imshow(im_convert(images[i]))  ax.set_title(classes[labels[i].item()])CIFA\n\n¶Optimizer 와 Criterion\n12criterion = nn.CrossEntropyLoss()optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n¶training\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061epochs = 12running_loss_history = []running_correct_history = []validation_running_loss_history = [] validation_running_correct_history = []for e in range(epochs):    running_loss = 0.0  running_correct = 0.0  validation_running_loss = 0.0  validation_running_correct = 0.0    for inputs, labels in training_loader:             inputs = inputs.to(device)    labels = labels.to(device)    outputs = model(inputs)    loss = criterion(outputs, labels)        optimizer.zero_grad()    loss.backward()    optimizer.step()        _, preds = torch.max(outputs, 1)        running_correct += torch.sum(preds == labels.data)    running_loss += loss.item()              else:        # 훈련팔 필요가 없으므로 메모리 절약    with torch.no_grad():            for val_input, val_label in validation_loader:                val_input = val_input.to(device)        val_label = val_label.to(device)        val_outputs = model(val_input)        val_loss = criterion(val_outputs, val_label)                _, val_preds = torch.max(val_outputs, 1)        validation_running_loss += val_loss.item()        validation_running_correct += torch.sum(val_preds == val_label.data)             epoch_loss = running_loss / len(training_loader)    epoch_acc = running_correct.float() / len(training_loader)    running_loss_history.append(epoch_loss)    running_correct_history.append(epoch_acc)        val_epoch_loss = validation_running_loss / len(validation_loader)    val_epoch_acc = validation_running_correct.float() / len(validation_loader)    validation_running_loss_history.append(val_epoch_loss)    validation_running_correct_history.append(val_epoch_acc)        print(\"===================================================\")    print(\"epoch: \", e + 1)    print(\"training loss: &#123;:.5f&#125;, acc: &#123;:5f&#125;\".format(epoch_loss, epoch_acc))    print(\"validation loss: &#123;:.5f&#125;, acc: &#123;:5f&#125;\".format(val_epoch_loss, val_epoch_acc))\n¶1st try\nLeNet을 활용하여, 기존에 손글씨를 분류했을 때 썼던 파라미터 그대로 해보자.\n¶Model\n123456789101112131415161718192021222324class LeNet(nn.Module):    def __init__(self):    super().__init__()    # RGB세개 1채널, 20개 특징 추출, filter 크기, stride 1    self.conv1 = nn.Conv2d(3, 20, 5, 1)    # 전에서 20개    self.conv2 = nn.Conv2d(20, 50, 5, 1)    self.fc1 = nn.Linear(5*5*50, 500)    # 0.5 가 권장 할 만하대    self.dropout1 = nn.Dropout(0.5)    self.fc2 = nn.Linear(500, 10)  def forward(self, x):    x = F.relu(self.conv1(x))    x = F.max_pool2d(x, 2, 2)    x = F.relu(self.conv2(x))    x = F.max_pool2d(x, 2, 2)    # flatten    x = x.view(-1, 5*5*50)    x = F.relu(self.fc1(x))    x = self.dropout1(x)    x = self.fc2(x)    return x\n¶결과\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748===================================================epoch:  1training loss: 1.51251, acc: 44.908001validation loss: 1.27473, acc: 54.189999===================================================epoch:  2training loss: 1.16539, acc: 58.480003validation loss: 1.07463, acc: 61.829998===================================================epoch:  3training loss: 1.00764, acc: 64.464005validation loss: 1.04436, acc: 63.349998===================================================epoch:  4training loss: 0.90411, acc: 68.162003validation loss: 0.96203, acc: 66.619995===================================================epoch:  5training loss: 0.82512, acc: 71.142006validation loss: 0.92654, acc: 67.889999===================================================epoch:  6training loss: 0.76343, acc: 73.138000validation loss: 0.90890, acc: 69.029999===================================================epoch:  7training loss: 0.70817, acc: 75.176003validation loss: 0.90005, acc: 69.639999===================================================epoch:  8training loss: 0.66021, acc: 76.596001validation loss: 0.91046, acc: 69.409996===================================================epoch:  9training loss: 0.61744, acc: 78.116005validation loss: 0.91911, acc: 69.799995===================================================epoch:  10training loss: 0.57813, acc: 79.522003validation loss: 0.94296, acc: 69.189995===================================================epoch:  11training loss: 0.53510, acc: 80.990005validation loss: 0.95957, acc: 69.209999===================================================epoch:  12training loss: 0.50244, acc: 82.116005validation loss: 0.98390, acc: 69.419998\n\n\n¶총평\n딱봐도 Overfitting이 일어났고, 정확도도 구리다.\n¶2nd Model\nConvolution을 하나더 추가해서, 특징을 조금더 뽑아내는 방향으로 바꿔보자.\n123456789101112131415161718192021222324class LeNet_2(nn.Module):    def __init__(self):    super().__init__()    # 32px 이었다가, conv를 거치면서 절반으로 감소    self.conv1 = nn.Conv2d(3, 16, 3, 1, padding=1)    self.conv2 = nn.Conv2d(16, 32, 3, 1, padding=1)    self.conv3 = nn.Conv2d(32, 64, 3, 1, padding=1)    self.fc1 = nn.Linear(4*4*64, 500)    self.dropout1 = nn.Dropout(0.5)    self.fc2 = nn.Linear(500, 10)      def forward(self, x):    x = F.relu(self.conv1(x))    x = F.max_pool2d(x, 2, 2)    x = F.relu(self.conv2(x))    x = F.max_pool2d(x, 2, 2)    x = F.relu(self.conv3(x))    x = F.max_pool2d(x, 2, 2)    x = x.view(-1, 4*4*64)    x = F.relu(self.fc1(x))    x = self.dropout1(x)    x = self.fc2(x)    return x\n첫번째 Conv에서는 입력채널이 3개, 추출할 filter는 3개이며 filter의 크기는 3, stride는 1이다. 그리고 padding을 1씩 넣어서 크기가 줄어드는 것을 방지했다.\n따라서 각각의 convolution을 거칠 때마다 입력값이 절반으로 줄어들게 된다. (MaxPooling 사이즈가 2, 2 이므로)\n\n\n\ninput\nconv1\npool1\nconv2\npool2\nconv3\npool3\n\n\n\n\n32\n32\n16\n16\n8\n8\n4\n\n\n\n¶결과\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748===================================================epoch:  1training loss: 1.51715, acc: 44.712002validation loss: 1.25653, acc: 55.230000===================================================epoch:  2training loss: 1.16654, acc: 58.526001validation loss: 1.09924, acc: 60.959999===================================================epoch:  3training loss: 1.02785, acc: 63.822002validation loss: 1.02541, acc: 64.019997===================================================epoch:  4training loss: 0.91954, acc: 67.690002validation loss: 1.01354, acc: 64.529999===================================================epoch:  5training loss: 0.84753, acc: 70.680000validation loss: 0.92927, acc: 67.639999===================================================epoch:  6training loss: 0.79165, acc: 71.830002validation loss: 0.88947, acc: 69.279999===================================================epoch:  7training loss: 0.73852, acc: 73.806000validation loss: 0.92085, acc: 68.559998===================================================epoch:  8training loss: 0.68945, acc: 75.670006validation loss: 0.91607, acc: 68.529999===================================================epoch:  9training loss: 0.64567, acc: 77.178001validation loss: 0.93162, acc: 69.290001===================================================epoch:  10training loss: 0.61021, acc: 78.222000validation loss: 0.89344, acc: 70.389999===================================================epoch:  11training loss: 0.57332, acc: 79.376007validation loss: 0.93702, acc: 70.189995===================================================epoch:  12training loss: 0.53661, acc: 80.696007validation loss: 0.92468, acc: 70.689995\n\n\n정확도가 향상된 모습이지만, 여전히 Overfitting이 발생하고 있다.\n¶3rd try\nData Augmentation, 데이터에 인위적인 변화를 주어서 학습이 용이하게 끔 해보자.\n\n1234567891011121314151617181920transform_train = transforms.Compose([transforms.Resize((32, 32)),                                      transforms.RandomHorizontalFlip(),                                      transforms.RandomRotation(10),                                      transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),                                      transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),                                      transforms.ToTensor(),                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                     ])transformer = transforms.Compose([transforms.Resize((32, 32)),                                  transforms.ToTensor(),                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                 ])training_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)validation_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transformer)training_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=100, shuffle=True)validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100, shuffle=False)\ntransform_train에 적용된 augmentation을 살펴보자\n\ntransforms.RandomHorizontalFlip() 0.5확률로 이미지를 뒤집음\ntransforms.RandomRotation(10) 10도 이하로 랜덤하게 기울인다.\ntransforms.RandomAffine(0, shear=10, scale=(0.8, 1.2) 기하학(…)에서 쓰이는 아핀변환이다.\n\ntransforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2) 밝기, 대비, 채도를 랜덤하게 조절한다.\n\n¶결과\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748===================================================epoch:  1training loss: 1.69155, acc: 38.206001validation loss: 1.47858, acc: 46.969997===================================================epoch:  2training loss: 1.39742, acc: 49.534004validation loss: 1.23282, acc: 54.919998===================================================epoch:  3training loss: 1.27040, acc: 54.270004validation loss: 1.14570, acc: 58.629997===================================================epoch:  4training loss: 1.17016, acc: 58.068005validation loss: 1.06811, acc: 61.609997===================================================epoch:  5training loss: 1.11306, acc: 60.408005validation loss: 1.02522, acc: 63.559998===================================================epoch:  6training loss: 1.07079, acc: 61.996002validation loss: 0.98546, acc: 65.559998===================================================epoch:  7training loss: 1.01881, acc: 63.968002validation loss: 0.91596, acc: 68.080002===================================================epoch:  8training loss: 0.98842, acc: 65.208000validation loss: 0.89914, acc: 68.000000===================================================epoch:  9training loss: 0.96484, acc: 65.940002validation loss: 0.88494, acc: 68.619995===================================================epoch:  10training loss: 0.93930, acc: 66.904007validation loss: 0.88999, acc: 68.830002===================================================epoch:  11training loss: 0.91366, acc: 67.650002validation loss: 0.84115, acc: 70.619995===================================================epoch:  12training loss: 0.89831, acc: 68.562004validation loss: 0.83667, acc: 70.750000\n\n\n어떻게 하면 정확도를 더 올릴 수 있을까~~~?\n","dateCreated":"2019-02-25T00:00:00+09:00","dateModified":"2019-02-25T09:03:38+09:00","datePublished":"2019-02-25T00:00:00+09:00","description":"Pytorch - 08) CIFAR 10\n\nCIFAR 10 는 열가지 단어별 이미지가 있는 데이터 셋이다. 기존에 손글씨를 분류하는 것 보다는 확실히 어려운 작업이 될 것이다.\n\n\n\n¶전처리 작업\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n\n\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom torch import ","headline":"Pytorch 08) - CIFAR 10 학습","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.yceffort.kr/2019/02/25/pytorch-08-CIFAR-10/"},"publisher":{"@type":"Organization","name":"yceffort","sameAs":["https://github.com/yceffort","mailto: root@yceffort.kr"],"image":"https://www.gravatar.com/avatar/f24f66c6311c477d8ac26a9ef346560c","logo":{"@type":"ImageObject","url":"https://www.gravatar.com/avatar/f24f66c6311c477d8ac26a9ef346560c"}},"url":"https://www.yceffort.kr/2019/02/25/pytorch-08-CIFAR-10/","keywords":"pytorch"}</script>
    <meta name="description" content="Pytorch - 08) CIFAR 10  CIFAR 10 는 열가지 단어별 이미지가 있는 데이터 셋이다. 기존에 손글씨를 분류하는 것 보다는 확실히 어려운 작업이 될 것이다.    ¶전처리 작업 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33">
<meta name="keywords" content="pytorch">
<meta property="og:type" content="blog">
<meta property="og:title" content="Pytorch 08) - CIFAR 10 학습">
<meta property="og:url" content="https://www.yceffort.kr/2019/02/25/pytorch-08-CIFAR-10/index.html">
<meta property="og:site_name" content="yceffort">
<meta property="og:description" content="Pytorch - 08) CIFAR 10  CIFAR 10 는 열가지 단어별 이미지가 있는 데이터 셋이다. 기존에 손글씨를 분류하는 것 보다는 확실히 어려운 작업이 될 것이다.    ¶전처리 작업 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/CIFAR10.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/CIFAR10-1.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/CIFAR10-2.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/CIFAR10-3.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/CIFAR10-4.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/CIFAR10-5.png">
<meta property="og:image" content="https://www.researchgate.net/publication/319413978/figure/fig2/AS:533727585333249@1504261980375/Data-augmentation-using-semantic-preserving-transformation-for-SBIR.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/CIFAR10-6.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/CIFAR10-7.png">
<meta property="og:image" content="https://www.yceffort.kr/images/2019/02/CIFAR10-8.png">
<meta property="og:updated_time" content="2019-02-25T00:03:38.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pytorch 08) - CIFAR 10 학습">
<meta name="twitter:description" content="Pytorch - 08) CIFAR 10  CIFAR 10 는 열가지 단어별 이미지가 있는 데이터 셋이다. 기존에 손글씨를 분류하는 것 보다는 확실히 어려운 작업이 될 것이다.    ¶전처리 작업 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33">
<meta name="twitter:image" content="https://www.yceffort.kr/images/2019/02/CIFAR10.png">
    
    
    
    
    
    <meta property="og:image" content="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=640" />
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/style-iyxsfxng5z2aqzamse6aps0lcii97y4op8hvyv9myltr058xvtcydusibtym.min.css">
    <!--STYLES END-->
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-139493546-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-139493546-1');
    </script>


    
</head>
    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
    

<header id="header" data-behavior="2">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/ ">yceffort</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
            <img class="header-picture" src="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=90" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->


    

<nav id="sidebar" data-behavior="2">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a href="/#about">
                    <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=110" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">yceffort</h4>
                
                    <h5 class="sidebar-profile-bio"><p>yceffort</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/ "
                            
                            title="Home"
                        >
                    
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-tags"
                            
                            title="Tags"
                        >
                    
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link open-algolia-search"
                             href="#search"
                            
                            title="Search"
                        >
                    
                        <i class="sidebar-button-icon fa fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Search</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/bookmark"
                            
                            title="Bookmark"
                        >
                    
                        <i class="sidebar-button-icon fa fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Bookmark</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="#about"
                            
                            title="About"
                        >
                    
                        <i class="sidebar-button-icon fa fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/yceffort" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto: root@yceffort.kr" target="_blank" rel="noopener" title="Mail">
                    
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/atom.xml"
                            
                            title="RSS"
                        >
                    
                        <i class="sidebar-button-icon fa fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="2"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            Pytorch 08) - CIFAR 10 학습
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2019-02-25T00:00:00+09:00">
	
		    Feb 25, 2019
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <p>Pytorch - 08) CIFAR 10</p>
<p>CIFAR 10 는 열가지 단어별 이미지가 있는 데이터 셋이다. 기존에 손글씨를 분류하는 것 보다는 확실히 어려운 작업이 될 것이다.</p>
<p><img src="/images/2019/02/CIFAR10.png" alt="CIFAR10"></p>
<h2 id="전처리-작업"><a class="header-anchor" href="#전처리-작업">¶</a>전처리 작업</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line">transformer = transforms.Compose([transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">                                  transforms.ToTensor(),</span><br><span class="line">                                  transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">                                 ])</span><br><span class="line"></span><br><span class="line">training_dataset = datasets.CIFAR10(root=<span class="string">'./data'</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transformer)</span><br><span class="line">validation_dataset = datasets.CIFAR10(root=<span class="string">'./data'</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transformer)</span><br><span class="line"></span><br><span class="line">training_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=<span class="number">100</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=<span class="number">100</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">im_convert</span><span class="params">(tensor)</span>:</span></span><br><span class="line">  image = tensor.clone().detach().numpy()</span><br><span class="line">  image = image.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line">  image = image * np.array([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>] + np.array([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]))</span><br><span class="line">  image = image.clip(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">  <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">"plane"</span>, <span class="string">"car"</span>, <span class="string">"bird"</span>, <span class="string">"cat"</span>, <span class="string">"deer"</span>, <span class="string">"dog"</span>, <span class="string">"frog"</span>, <span class="string">"horse"</span>, <span class="string">"ship"</span>, <span class="string">"truck"</span>)</span><br><span class="line"></span><br><span class="line">dataiter = iter(training_loader)</span><br><span class="line">images, labels = dataiter.next()</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">25</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">20</span>):</span><br><span class="line">  <span class="comment"># row 2 column 10</span></span><br><span class="line">  ax = fig.add_subplot(<span class="number">2</span>, <span class="number">10</span>, i+<span class="number">1</span>, xticks=[], yticks=[])</span><br><span class="line">  plt.imshow(im_convert(images[i]))</span><br><span class="line">  ax.set_title(classes[labels[i].item()])CIFA</span><br></pre></td></tr></table></figure>
<p><img src="/images/2019/02/CIFAR10-1.png" alt="CIFAR10-1"></p>
<h2 id="optimizer-와-criterion"><a class="header-anchor" href="#optimizer-와-criterion">¶</a>Optimizer 와 Criterion</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<h2 id="training"><a class="header-anchor" href="#training">¶</a>training</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">12</span></span><br><span class="line">running_loss_history = []</span><br><span class="line">running_correct_history = []</span><br><span class="line">validation_running_loss_history = [] </span><br><span class="line">validation_running_correct_history = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">  </span><br><span class="line">  running_loss = <span class="number">0.0</span></span><br><span class="line">  running_correct = <span class="number">0.0</span></span><br><span class="line">  validation_running_loss = <span class="number">0.0</span></span><br><span class="line">  validation_running_correct = <span class="number">0.0</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> training_loader:    </span><br><span class="line">     </span><br><span class="line">    inputs = inputs.to(device)</span><br><span class="line">    labels = labels.to(device)</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    _, preds = torch.max(outputs, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    running_correct += torch.sum(preds == labels.data)</span><br><span class="line">    running_loss += loss.item()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">  <span class="keyword">else</span>:    </span><br><span class="line">    <span class="comment"># 훈련팔 필요가 없으므로 메모리 절약</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">for</span> val_input, val_label <span class="keyword">in</span> validation_loader:</span><br><span class="line">        </span><br><span class="line">        val_input = val_input.to(device)</span><br><span class="line">        val_label = val_label.to(device)</span><br><span class="line">        val_outputs = model(val_input)</span><br><span class="line">        val_loss = criterion(val_outputs, val_label)</span><br><span class="line">        </span><br><span class="line">        _, val_preds = torch.max(val_outputs, <span class="number">1</span>)</span><br><span class="line">        validation_running_loss += val_loss.item()</span><br><span class="line">        validation_running_correct += torch.sum(val_preds == val_label.data) </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    epoch_loss = running_loss / len(training_loader)</span><br><span class="line">    epoch_acc = running_correct.float() / len(training_loader)</span><br><span class="line">    running_loss_history.append(epoch_loss)</span><br><span class="line">    running_correct_history.append(epoch_acc)</span><br><span class="line">    </span><br><span class="line">    val_epoch_loss = validation_running_loss / len(validation_loader)</span><br><span class="line">    val_epoch_acc = validation_running_correct.float() / len(validation_loader)</span><br><span class="line">    validation_running_loss_history.append(val_epoch_loss)</span><br><span class="line">    validation_running_correct_history.append(val_epoch_acc)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"==================================================="</span>)</span><br><span class="line">    print(<span class="string">"epoch: "</span>, e + <span class="number">1</span>)</span><br><span class="line">    print(<span class="string">"training loss: &#123;:.5f&#125;, acc: &#123;:5f&#125;"</span>.format(epoch_loss, epoch_acc))</span><br><span class="line">    print(<span class="string">"validation loss: &#123;:.5f&#125;, acc: &#123;:5f&#125;"</span>.format(val_epoch_loss, val_epoch_acc))</span><br></pre></td></tr></table></figure>
<h2 id="1st-try"><a class="header-anchor" href="#1st-try">¶</a>1st try</h2>
<p>LeNet을 활용하여, 기존에 손글씨를 분류했을 때 썼던 파라미터 그대로 해보자.</p>
<h3 id="model"><a class="header-anchor" href="#model">¶</a>Model</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    super().__init__()</span><br><span class="line">    <span class="comment"># RGB세개 1채널, 20개 특징 추출, filter 크기, stride 1</span></span><br><span class="line">    self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">20</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 전에서 20개</span></span><br><span class="line">    self.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">50</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">    self.fc1 = nn.Linear(<span class="number">5</span>*<span class="number">5</span>*<span class="number">50</span>, <span class="number">500</span>)</span><br><span class="line">    <span class="comment"># 0.5 가 권장 할 만하대</span></span><br><span class="line">    self.dropout1 = nn.Dropout(<span class="number">0.5</span>)</span><br><span class="line">    self.fc2 = nn.Linear(<span class="number">500</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    x = F.relu(self.conv1(x))</span><br><span class="line">    x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    x = F.relu(self.conv2(x))</span><br><span class="line">    x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># flatten</span></span><br><span class="line">    x = x.view(<span class="number">-1</span>, <span class="number">5</span>*<span class="number">5</span>*<span class="number">50</span>)</span><br><span class="line">    x = F.relu(self.fc1(x))</span><br><span class="line">    x = self.dropout1(x)</span><br><span class="line">    x = self.fc2(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="결과"><a class="header-anchor" href="#결과">¶</a>결과</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">===================================================</span><br><span class="line">epoch:  1</span><br><span class="line">training loss: 1.51251, acc: 44.908001</span><br><span class="line">validation loss: 1.27473, acc: 54.189999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  2</span><br><span class="line">training loss: 1.16539, acc: 58.480003</span><br><span class="line">validation loss: 1.07463, acc: 61.829998</span><br><span class="line">===================================================</span><br><span class="line">epoch:  3</span><br><span class="line">training loss: 1.00764, acc: 64.464005</span><br><span class="line">validation loss: 1.04436, acc: 63.349998</span><br><span class="line">===================================================</span><br><span class="line">epoch:  4</span><br><span class="line">training loss: 0.90411, acc: 68.162003</span><br><span class="line">validation loss: 0.96203, acc: 66.619995</span><br><span class="line">===================================================</span><br><span class="line">epoch:  5</span><br><span class="line">training loss: 0.82512, acc: 71.142006</span><br><span class="line">validation loss: 0.92654, acc: 67.889999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  6</span><br><span class="line">training loss: 0.76343, acc: 73.138000</span><br><span class="line">validation loss: 0.90890, acc: 69.029999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  7</span><br><span class="line">training loss: 0.70817, acc: 75.176003</span><br><span class="line">validation loss: 0.90005, acc: 69.639999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  8</span><br><span class="line">training loss: 0.66021, acc: 76.596001</span><br><span class="line">validation loss: 0.91046, acc: 69.409996</span><br><span class="line">===================================================</span><br><span class="line">epoch:  9</span><br><span class="line">training loss: 0.61744, acc: 78.116005</span><br><span class="line">validation loss: 0.91911, acc: 69.799995</span><br><span class="line">===================================================</span><br><span class="line">epoch:  10</span><br><span class="line">training loss: 0.57813, acc: 79.522003</span><br><span class="line">validation loss: 0.94296, acc: 69.189995</span><br><span class="line">===================================================</span><br><span class="line">epoch:  11</span><br><span class="line">training loss: 0.53510, acc: 80.990005</span><br><span class="line">validation loss: 0.95957, acc: 69.209999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  12</span><br><span class="line">training loss: 0.50244, acc: 82.116005</span><br><span class="line">validation loss: 0.98390, acc: 69.419998</span><br></pre></td></tr></table></figure>
<p><img src="/images/2019/02/CIFAR10-2.png" alt="CIFAR10-2"></p>
<p><img src="/images/2019/02/CIFAR10-3.png" alt="CIFAR10-3"></p>
<h3 id="총평"><a class="header-anchor" href="#총평">¶</a>총평</h3>
<p>딱봐도 Overfitting이 일어났고, 정확도도 구리다.</p>
<h2 id="2nd-model"><a class="header-anchor" href="#2nd-model">¶</a>2nd Model</h2>
<p>Convolution을 하나더 추가해서, 특징을 조금더 뽑아내는 방향으로 바꿔보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet_2</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    super().__init__()</span><br><span class="line">    <span class="comment"># 32px 이었다가, conv를 거치면서 절반으로 감소</span></span><br><span class="line">    self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, <span class="number">3</span>, <span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">    self.conv2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">    self.conv3 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">    self.fc1 = nn.Linear(<span class="number">4</span>*<span class="number">4</span>*<span class="number">64</span>, <span class="number">500</span>)</span><br><span class="line">    self.dropout1 = nn.Dropout(<span class="number">0.5</span>)</span><br><span class="line">    self.fc2 = nn.Linear(<span class="number">500</span>, <span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    x = F.relu(self.conv1(x))</span><br><span class="line">    x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    x = F.relu(self.conv2(x))</span><br><span class="line">    x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    x = F.relu(self.conv3(x))</span><br><span class="line">    x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    x = x.view(<span class="number">-1</span>, <span class="number">4</span>*<span class="number">4</span>*<span class="number">64</span>)</span><br><span class="line">    x = F.relu(self.fc1(x))</span><br><span class="line">    x = self.dropout1(x)</span><br><span class="line">    x = self.fc2(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>첫번째 Conv에서는 입력채널이 3개, 추출할 filter는 3개이며 filter의 크기는 3, stride는 1이다. 그리고 padding을 1씩 넣어서 크기가 줄어드는 것을 방지했다.</p>
<p>따라서 각각의 convolution을 거칠 때마다 입력값이 절반으로 줄어들게 된다. (MaxPooling 사이즈가 2, 2 이므로)</p>
<table>
<thead>
<tr>
<th style="text-align:center">input</th>
<th style="text-align:center">conv1</th>
<th style="text-align:center">pool1</th>
<th style="text-align:center">conv2</th>
<th style="text-align:center">pool2</th>
<th style="text-align:center">conv3</th>
<th style="text-align:center">pool3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">32</td>
<td style="text-align:center">32</td>
<td style="text-align:center">16</td>
<td style="text-align:center">16</td>
<td style="text-align:center">8</td>
<td style="text-align:center">8</td>
<td style="text-align:center">4</td>
</tr>
</tbody>
</table>
<h3 id="결과-v2"><a class="header-anchor" href="#결과-v2">¶</a>결과</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">===================================================</span><br><span class="line">epoch:  1</span><br><span class="line">training loss: 1.51715, acc: 44.712002</span><br><span class="line">validation loss: 1.25653, acc: 55.230000</span><br><span class="line">===================================================</span><br><span class="line">epoch:  2</span><br><span class="line">training loss: 1.16654, acc: 58.526001</span><br><span class="line">validation loss: 1.09924, acc: 60.959999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  3</span><br><span class="line">training loss: 1.02785, acc: 63.822002</span><br><span class="line">validation loss: 1.02541, acc: 64.019997</span><br><span class="line">===================================================</span><br><span class="line">epoch:  4</span><br><span class="line">training loss: 0.91954, acc: 67.690002</span><br><span class="line">validation loss: 1.01354, acc: 64.529999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  5</span><br><span class="line">training loss: 0.84753, acc: 70.680000</span><br><span class="line">validation loss: 0.92927, acc: 67.639999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  6</span><br><span class="line">training loss: 0.79165, acc: 71.830002</span><br><span class="line">validation loss: 0.88947, acc: 69.279999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  7</span><br><span class="line">training loss: 0.73852, acc: 73.806000</span><br><span class="line">validation loss: 0.92085, acc: 68.559998</span><br><span class="line">===================================================</span><br><span class="line">epoch:  8</span><br><span class="line">training loss: 0.68945, acc: 75.670006</span><br><span class="line">validation loss: 0.91607, acc: 68.529999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  9</span><br><span class="line">training loss: 0.64567, acc: 77.178001</span><br><span class="line">validation loss: 0.93162, acc: 69.290001</span><br><span class="line">===================================================</span><br><span class="line">epoch:  10</span><br><span class="line">training loss: 0.61021, acc: 78.222000</span><br><span class="line">validation loss: 0.89344, acc: 70.389999</span><br><span class="line">===================================================</span><br><span class="line">epoch:  11</span><br><span class="line">training loss: 0.57332, acc: 79.376007</span><br><span class="line">validation loss: 0.93702, acc: 70.189995</span><br><span class="line">===================================================</span><br><span class="line">epoch:  12</span><br><span class="line">training loss: 0.53661, acc: 80.696007</span><br><span class="line">validation loss: 0.92468, acc: 70.689995</span><br></pre></td></tr></table></figure>
<p><img src="/images/2019/02/CIFAR10-4.png" alt="CIFAR10-4"></p>
<p><img src="/images/2019/02/CIFAR10-5.png" alt="CIFAR10-5"></p>
<p>정확도가 향상된 모습이지만, 여전히 Overfitting이 발생하고 있다.</p>
<h2 id="3rd-try"><a class="header-anchor" href="#3rd-try">¶</a>3rd try</h2>
<p>Data Augmentation, 데이터에 인위적인 변화를 주어서 학습이 용이하게 끔 해보자.</p>
<p><img src="https://www.researchgate.net/publication/319413978/figure/fig2/AS:533727585333249@1504261980375/Data-augmentation-using-semantic-preserving-transformation-for-SBIR.png" alt="data-augmentation"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">transform_train = transforms.Compose([transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">                                      transforms.RandomHorizontalFlip(),</span><br><span class="line">                                      transforms.RandomRotation(<span class="number">10</span>),</span><br><span class="line">                                      transforms.RandomAffine(<span class="number">0</span>, shear=<span class="number">10</span>, scale=(<span class="number">0.8</span>, <span class="number">1.2</span>)),</span><br><span class="line">                                      transforms.ColorJitter(brightness=<span class="number">0.2</span>, contrast=<span class="number">0.2</span>, saturation=<span class="number">0.2</span>),</span><br><span class="line">                                      transforms.ToTensor(),</span><br><span class="line">                                      transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">                                     ])</span><br><span class="line"></span><br><span class="line">transformer = transforms.Compose([transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">                                  transforms.ToTensor(),</span><br><span class="line">                                  transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))</span><br><span class="line">                                 ])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">training_dataset = datasets.CIFAR10(root=<span class="string">'./data'</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform_train)</span><br><span class="line">validation_dataset = datasets.CIFAR10(root=<span class="string">'./data'</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transformer)</span><br><span class="line"></span><br><span class="line">training_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=<span class="number">100</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=<span class="number">100</span>, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p><code>transform_train</code>에 적용된 augmentation을 살펴보자</p>
<ul>
<li><code>transforms.RandomHorizontalFlip()</code> 0.5확률로 이미지를 뒤집음</li>
<li><code>transforms.RandomRotation(10)</code> 10도 이하로 랜덤하게 기울인다.</li>
<li><code>transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)</code> 기하학(…)에서 쓰이는 아핀변환이다.<br>
<img src="/images/2019/02/CIFAR10-6.png" alt="CIFAR10-6"></li>
<li><code>transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)</code> 밝기, 대비, 채도를 랜덤하게 조절한다.</li>
</ul>
<h3 id="결과-v3"><a class="header-anchor" href="#결과-v3">¶</a>결과</h3>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">===================================================</span><br><span class="line">epoch:  1</span><br><span class="line">training loss: 1.69155, acc: 38.206001</span><br><span class="line">validation loss: 1.47858, acc: 46.969997</span><br><span class="line">===================================================</span><br><span class="line">epoch:  2</span><br><span class="line">training loss: 1.39742, acc: 49.534004</span><br><span class="line">validation loss: 1.23282, acc: 54.919998</span><br><span class="line">===================================================</span><br><span class="line">epoch:  3</span><br><span class="line">training loss: 1.27040, acc: 54.270004</span><br><span class="line">validation loss: 1.14570, acc: 58.629997</span><br><span class="line">===================================================</span><br><span class="line">epoch:  4</span><br><span class="line">training loss: 1.17016, acc: 58.068005</span><br><span class="line">validation loss: 1.06811, acc: 61.609997</span><br><span class="line">===================================================</span><br><span class="line">epoch:  5</span><br><span class="line">training loss: 1.11306, acc: 60.408005</span><br><span class="line">validation loss: 1.02522, acc: 63.559998</span><br><span class="line">===================================================</span><br><span class="line">epoch:  6</span><br><span class="line">training loss: 1.07079, acc: 61.996002</span><br><span class="line">validation loss: 0.98546, acc: 65.559998</span><br><span class="line">===================================================</span><br><span class="line">epoch:  7</span><br><span class="line">training loss: 1.01881, acc: 63.968002</span><br><span class="line">validation loss: 0.91596, acc: 68.080002</span><br><span class="line">===================================================</span><br><span class="line">epoch:  8</span><br><span class="line">training loss: 0.98842, acc: 65.208000</span><br><span class="line">validation loss: 0.89914, acc: 68.000000</span><br><span class="line">===================================================</span><br><span class="line">epoch:  9</span><br><span class="line">training loss: 0.96484, acc: 65.940002</span><br><span class="line">validation loss: 0.88494, acc: 68.619995</span><br><span class="line">===================================================</span><br><span class="line">epoch:  10</span><br><span class="line">training loss: 0.93930, acc: 66.904007</span><br><span class="line">validation loss: 0.88999, acc: 68.830002</span><br><span class="line">===================================================</span><br><span class="line">epoch:  11</span><br><span class="line">training loss: 0.91366, acc: 67.650002</span><br><span class="line">validation loss: 0.84115, acc: 70.619995</span><br><span class="line">===================================================</span><br><span class="line">epoch:  12</span><br><span class="line">training loss: 0.89831, acc: 68.562004</span><br><span class="line">validation loss: 0.83667, acc: 70.750000</span><br></pre></td></tr></table></figure>
<p><img src="/images/2019/02/CIFAR10-7.png" alt="CIFAR10-7"></p>
<p><img src="/images/2019/02/CIFAR10-8.png" alt="CIFAR10-8"></p>
<p>어떻게 하면 정확도를 더 올릴 수 있을까~~~?</p>

            

        </div>
    </div>

    <style>.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#000000 !important;background-color:#FFFFFF !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 0px 9px !important;font-size: 17px !important;letter-spacing:-0.08px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:'Lato', sans-serif !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#000000 !important;}</style><link href="https://fonts.googleapis.com/css?family=Lato&subset=latin,latin-ext" rel="stylesheet">
    <center style="display: block; text-align: -webkit-center; margin-top: 20px;">
        <a class="bmc-button" target="_blank" href="https://www.buymeacoffee.com/foryeffort"><img src="https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg" alt="coffee for yceffort"><span style="margin-left:5px">coffee for yceffort</span></a>
    </center>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-link" href="/tags/pytorch/">pytorch</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2019/02/26/pytorch-09-transfer-learning/" data-tooltip="Pytorch 09) - Transfer Learning" aria-label="PREVIOUS: Pytorch 09) - Transfer Learning">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2019/02/21/pytorch-06-convolutional-neural-network(1)/" data-tooltip="Pytorch 06) - Convolutional Neural Network (1)" aria-label="NEXT: Pytorch 06) - Convolutional Neural Network (1)">
                
                    <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://www.yceffort.kr/2019/02/25/pytorch-08-CIFAR-10/" title="Share on Facebook">
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://www.yceffort.kr/2019/02/25/pytorch-08-CIFAR-10/" title="Share on Twitter">
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2019 yceffort. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="2">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2019/02/26/pytorch-09-transfer-learning/" data-tooltip="Pytorch 09) - Transfer Learning" aria-label="PREVIOUS: Pytorch 09) - Transfer Learning">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2019/02/21/pytorch-06-convolutional-neural-network(1)/" data-tooltip="Pytorch 06) - Convolutional Neural Network (1)" aria-label="NEXT: Pytorch 06) - Convolutional Neural Network (1)">
                
                    <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://www.yceffort.kr/2019/02/25/pytorch-08-CIFAR-10/" title="Share on Facebook">
                    <i class="fab fa-facebook" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://www.yceffort.kr/2019/02/25/pytorch-08-CIFAR-10/" title="Share on Twitter">
                    <i class="fab fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                
    <div id="share-options-bar" class="share-options-bar" data-behavior="2">
        <i id="btn-close-shareoptions" class="fa fa-times"></i>
        <ul class="share-options">
            
                
                
                <li class="share-option">
                    <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://www.yceffort.kr/2019/02/25/pytorch-08-CIFAR-10/">
                        <i class="fab fa-facebook" aria-hidden="true"></i><span>Share on Facebook</span>
                    </a>
                </li>
            
                
                
                <li class="share-option">
                    <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https://www.yceffort.kr/2019/02/25/pytorch-08-CIFAR-10/">
                        <i class="fab fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                    </a>
                </li>
            
        </ul>
    </div>


            
        </div>
        


    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="https://www.gravatar.com/avatar/6b0848c9324388ed7ca5157d9d6e67c6?s=110" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">yceffort</h4>
        
            <div id="about-card-bio"><p>yceffort</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>programmer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Korea
            </div>
        
    </div>
</div>

        
            <div id="algolia-search-modal" class="modal-container">
    <div class="modal">
        <div class="modal-header">
            <span class="close-button"><i class="fa fa-times"></i></span>
            <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
                <span class="searchby-algolia-text text-color-light text-small">by</span>
                <img class="searchby-algolia-logo" src="https://community.algolia.com/wordpress/img/community-badge.svg">
            </a>
            <i class="search-icon fa fa-search"></i>
            <form id="algolia-search-form">
                <input type="text" id="algolia-search-input" name="search"
                    class="form-control input--large search-input" placeholder="Search "
                    />
            </form>
        </div>
        <div class="modal-body">
            <div class="no-result text-color-light text-center">no post found</div>
            <div class="results">
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/Levenshtein-distance/">
                            <h3 class="media-heading">두 String의 유사도를 측정해보자 - Levenshtein distance</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/Reactivex-subject/">
                            <h3 class="media-heading">ReactiveX) Subject</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/ReactiveX-Observable/">
                            <h3 class="media-heading">ReactiveX) Observable</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/bitcoin-btcd-bitcoin-cli/">
                            <h3 class="media-heading">Bitcoin) BTCD와 bitcoin-cli (bitcoin core)의 차이</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/compare-string-with-voice/">
                            <h3 class="media-heading">발음 기반으로 String의 유사도를 비교해 보자.</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/i-bought-bitcoin-and/">
                            <h3 class="media-heading">Bitcoin) 비트코인 샀던 후기</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/some-trick-delphi/">
                            <h3 class="media-heading">Delphi) Some tricks</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/05/31/tracking-bitcoin-core-sync/">
                            <h3 class="media-heading">Bitcoin) Bitcoin-core의 Sync를 동기화 해보자.</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 31, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/06/01/golang-structure-embedding/">
                            <h3 class="media-heading">GoLang) 구조체와 임베딩</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Jun 1, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://www.yceffort.kr/2018/06/17/bitcoin-white-paper-summary/">
                            <h3 class="media-heading">Bitcoin) 비트코인 백서 요약</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Jun 17, 2018
                                
                            </span>
                        </span>
                        <!-- <div class="media-content hide-xs font-merryweather"></div> -->
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
            </div>
        </div>
        <div class="modal-footer">
            <p class="results-count text-medium"
                data-message-zero="no post found"
                data-message-one="1 post found"
                data-message-other="{n} posts found">
                252 posts found
            </p>
        </div>
    </div>
</div>

        
        
<div id="cover" style="background-image:url('https://photos.smugmug.com/Galleries/All/i-m7cLXBm/0/X3/Lights%20of%20Lyngen-X3.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/script-x1zkdpaoieempqljgobpkeq95zi4mqk1sxpehbfxheuw5zbkhl7yw1l7engd.min.js"></script>
<!--SCRIPTS END-->

    
        <script>
             var disqus_config = function () {
                 this.page.url = 'https://www.yceffort.kr/2019/02/25/pytorch-08-CIFAR-10/';
                 
                    this.page.identifier = '2019/02/25/pytorch-08-CIFAR-10/';
                 
             };
            (function() {
                var d = document, s = d.createElement('script');
                var disqus_shortname = 'https-www-yceffort-kr';
                s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
    


    <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.14.1/moment-with-locales.min.js"></script>
    <script src="//cdn.jsdelivr.net/algoliasearch/3/algoliasearch.min.js"></script>
    <script>
        var algoliaClient = algoliasearch('LA1F1N8028', 'a69ce72946da4962e0d62d5a662a0c06');
        var algoliaIndex = algoliaClient.initIndex('yceffort_blog');
    </script>


    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
